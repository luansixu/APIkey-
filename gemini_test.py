"""
AI API å¯†é’¥å…¨èƒ½æµ‹è¯•å·¥å…· v4.0
ç›´æ¥åœ¨ç»ˆç«¯è¿è¡Œ: py gemini_test.py [API_KEY]
æ”¯æŒ: Google Gemini / OpenAI / ç¡…åŸºæµåŠ¨ / DeepSeek / Moonshot / æ™ºè°± / Groq / xAI ç­‰
åŠŸèƒ½: è‡ªåŠ¨è¯†åˆ«æœåŠ¡å•† Â· æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§ Â· é…é¢åååˆ†æ Â· Token éœ€æ±‚è®¡ç®—
"""

import json
import sys
import time
import os
import ssl
import socket
import urllib.request

# â”€â”€â”€ ä¾èµ–æ£€æŸ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

try:
    import requests
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
except ImportError:
    print("æ­£åœ¨å®‰è£… requests åº“...")
    os.system(f"{sys.executable} -m pip install requests -q")
    import requests
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# â”€â”€â”€ é¢œè‰²å·¥å…· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class C:
    RESET   = "\033[0m"
    BOLD    = "\033[1m"
    DIM     = "\033[2m"
    RED     = "\033[91m"
    GREEN   = "\033[92m"
    YELLOW  = "\033[93m"
    BLUE    = "\033[94m"
    MAGENTA = "\033[95m"
    CYAN    = "\033[96m"
    WHITE   = "\033[97m"
    GRAY    = "\033[90m"
    BG_GREEN  = "\033[42m"
    BG_RED    = "\033[41m"
    BG_YELLOW = "\033[43m"
    BG_BLUE   = "\033[44m"

if sys.platform == "win32":
    try:
        import ctypes
        kernel32 = ctypes.windll.kernel32
        kernel32.SetConsoleMode(kernel32.GetStdHandle(-11), 7)
    except Exception:
        pass

def c(text, color):
    return f"{color}{text}{C.RESET}"

# â”€â”€â”€ å·¥å…·å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fmt_tokens(num):
    if num is None:
        return "  -  "
    if num >= 1_000_000:
        return f"{num / 1_000_000:.1f}M"
    if num >= 1_000:
        return f"{num // 1_000}K"
    return str(num)

def progress_bar(current, total, width=30, label=""):
    filled = int(width * current / total) if total else 0
    bar = "â–ˆ" * filled + "â–‘" * (width - filled)
    pct = int(100 * current / total) if total else 0
    sys.stdout.write(f"\r  {c(bar, C.BLUE)} {c(f'{pct:3d}%', C.WHITE)} {c(f'({current}/{total})', C.GRAY)} {c(label[:40], C.GRAY)}    ")
    sys.stdout.flush()

def clear_line():
    sys.stdout.write("\r" + " " * 100 + "\r")
    sys.stdout.flush()

def divider(char="â”€", length=62):
    print(c(f"  {char * length}", C.GRAY))

def safe_exit(code=0):
    """å®‰å…¨é€€å‡ºï¼šæš‚åœç­‰å¾…ç”¨æˆ·æŒ‰é”®ï¼Œé˜²æ­¢çª—å£é—ªé€€"""
    print()
    try:
        input(c("  æŒ‰å›è½¦é”®é€€å‡º...", C.GRAY))
    except (EOFError, KeyboardInterrupt):
        pass
    sys.exit(code)

def print_header():
    print()
    print(c("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.BLUE))
    print(c("  â•‘", C.BLUE) + c("          AI API å¯†é’¥å…¨èƒ½æµ‹è¯•å·¥å…·  ", C.BOLD) + c("v4.0", C.CYAN) + c("                    ", C.BOLD) + c("â•‘", C.BLUE))
    print(c("  â•‘", C.BLUE) + c("   è‡ªåŠ¨è¯†åˆ«æœåŠ¡å•† Â· æµ‹è¯•æ¨¡å‹ Â· éªŒè¯å¯ç”¨æ€§ Â· é…é¢åˆ†æ        ", C.GRAY) + c("â•‘", C.BLUE))
    print(c("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.BLUE))
    print()

# â”€â”€â”€ æœåŠ¡å•†æ³¨å†Œä¸è‡ªåŠ¨æ£€æµ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

FORMAT_GEMINI = "gemini"
FORMAT_OPENAI = "openai"

# é€šè¿‡å¯†é’¥å‰ç¼€å¯ç›´æ¥è¯†åˆ«çš„æœåŠ¡å•†
PROVIDER_BY_PREFIX = [
    {"prefix": "AIza",      "name": "Google Gemini",     "icon": "ğŸ”µ",
     "base_url": "https://generativelanguage.googleapis.com/v1beta",
     "format": FORMAT_GEMINI, "needs_proxy_cn": True},
    {"prefix": "sk-ant-",   "name": "Anthropic Claude",  "icon": "ğŸŸ¤",
     "base_url": "https://api.anthropic.com/v1",
     "format": "anthropic",   "needs_proxy_cn": True},
    {"prefix": "AKID",      "name": "è…¾è®¯äº‘",            "icon": "ğŸ§",
     "base_url": "",
     "format": "tencent_secret", "needs_proxy_cn": False},
    {"prefix": "gsk_",      "name": "Groq",              "icon": "ğŸŸ ",
     "base_url": "https://api.groq.com/openai/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": True},
    {"prefix": "xai-",      "name": "xAI (Grok)",        "icon": "âšª",
     "base_url": "https://api.x.ai/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": True},
]

# sk- é€šç”¨å‰ç¼€éœ€è¦é€ä¸€æ¢æµ‹çš„æœåŠ¡å•†ï¼ˆæŒ‰å¸¸è§åº¦æ’åºï¼‰
PROBE_PROVIDERS = [
    {"name": "ç¡…åŸºæµåŠ¨",      "icon": "ğŸ”·", "base_url": "https://api.siliconflow.cn/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": False},
    {"name": "DeepSeek",     "icon": "ğŸ”¹", "base_url": "https://api.deepseek.com",
     "format": FORMAT_OPENAI, "needs_proxy_cn": False},
    {"name": "OpenAI",       "icon": "ğŸŸ¢", "base_url": "https://api.openai.com/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": True},
    {"name": "è…¾è®¯äº‘æ··å…ƒ",    "icon": "ğŸ§", "base_url": "https://api.hunyuan.cloud.tencent.com/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": False},
    {"name": "Moonshot",     "icon": "ğŸŒ™", "base_url": "https://api.moonshot.cn/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": False},
    {"name": "æ™ºè°± AI",      "icon": "ğŸŸ£", "base_url": "https://open.bigmodel.cn/api/paas/v4",
     "format": FORMAT_OPENAI, "needs_proxy_cn": False},
    {"name": "é›¶ä¸€ä¸‡ç‰©",      "icon": "ğŸŒ", "base_url": "https://api.lingyiwanwu.com/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": False},
    {"name": "ç™¾å·",         "icon": "ğŸŒŠ", "base_url": "https://api.baichuan-ai.com/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": False},
    {"name": "é˜¿é‡Œäº‘ç™¾ç‚¼",    "icon": "â˜ï¸",  "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": False},
    {"name": "è®¯é£æ˜Ÿç«",      "icon": "âœ¨", "base_url": "https://spark-api-open.xf-yun.com/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": False},
    {"name": "ç«å±±å¼•æ“",      "icon": "ğŸŒ‹", "base_url": "https://ark.cn-beijing.volces.com/api/v3",
     "format": FORMAT_OPENAI, "needs_proxy_cn": False},
    {"name": "Together AI",  "icon": "ğŸ¤", "base_url": "https://api.together.xyz/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": True},
    {"name": "Mistral",      "icon": "â“‚ï¸",  "base_url": "https://api.mistral.ai/v1",
     "format": FORMAT_OPENAI, "needs_proxy_cn": True},
]


def detect_provider_by_prefix(api_key):
    """é€šè¿‡å¯†é’¥å‰ç¼€ç›´æ¥è¯†åˆ«æœåŠ¡å•†ï¼ˆæ— ç½‘ç»œè¯·æ±‚ï¼‰"""
    for p in PROVIDER_BY_PREFIX:
        if api_key.startswith(p["prefix"]):
            return dict(p)
    if api_key.startswith("sk-proj-") or api_key.startswith("sk-svcacct-"):
        return {"name": "OpenAI", "icon": "ğŸŸ¢",
                "base_url": "https://api.openai.com/v1",
                "format": FORMAT_OPENAI, "needs_proxy_cn": True}
    return None


def probe_openai_providers(api_key):
    """æ¢æµ‹ sk- å¯†é’¥å¯¹åº”çš„ OpenAI å…¼å®¹æœåŠ¡å•†ã€‚
    é€ä¸€å°è¯•å„æœåŠ¡å•†çš„ /models ç«¯ç‚¹ï¼Œé¦–ä¸ªè¿”å›æœ‰æ•ˆå“åº”çš„å³ä¸ºç›®æ ‡ã€‚"""
    for p in PROBE_PROVIDERS:
        name = p["name"]
        base_url = p["base_url"]
        domain = base_url.split("//")[1].split("/")[0] if "//" in base_url else base_url

        sys.stdout.write(f"    å°è¯• {c(f'{name:<12s}', C.WHITE)} ({c(domain, C.GRAY)})  ")
        sys.stdout.flush()

        try:
            resp = _session.get(
                f"{base_url}/models",
                headers={"Authorization": f"Bearer {api_key}"},
                timeout=6,
            )
            if resp.status_code == 200:
                data = resp.json()
                if data.get("data") is not None or data.get("models") is not None or data.get("object"):
                    print(c("âœ“ åŒ¹é…!", C.GREEN + C.BOLD))
                    return dict(p)
                else:
                    print(c("âœ— å“åº”å¼‚å¸¸", C.YELLOW))
            elif resp.status_code in (401, 403):
                print(c("âœ— è®¤è¯å¤±è´¥", C.GRAY))
            elif resp.status_code == 404:
                print(c("âœ— ç«¯ç‚¹ä¸å­˜åœ¨", C.GRAY))
            else:
                print(c(f"âœ— HTTP {resp.status_code}", C.GRAY))
        except requests.exceptions.Timeout:
            print(c("âœ— è¶…æ—¶", C.GRAY))
        except requests.exceptions.ConnectionError:
            print(c("âœ— è¿æ¥å¤±è´¥", C.GRAY))
        except Exception as e:
            print(c(f"âœ— {str(e)[:30]}", C.GRAY))
    return None


def auto_detect_provider(api_key, custom_url=None):
    """å…¨è‡ªåŠ¨è¯†åˆ« API æœåŠ¡å•†ã€‚
    1. è‹¥ç”¨æˆ·æŒ‡å®šäº†è‡ªå®šä¹‰ URL â†’ ç›´æ¥ä½¿ç”¨
    2. æŒ‰å¯†é’¥å‰ç¼€åŒ¹é… â†’ ç›´æ¥è¯†åˆ«
    3. é€šç”¨ sk- å‰ç¼€ â†’ é€ä¸€æ¢æµ‹
    """
    # ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®š URL
    if custom_url:
        fmt = FORMAT_GEMINI if api_key.startswith("AIza") else FORMAT_OPENAI
        provider = {"name": "è‡ªå®šä¹‰", "icon": "ğŸ”§", "base_url": custom_url,
                     "format": fmt, "needs_proxy_cn": False}
        print_detected_provider(provider)
        return provider

    print()
    print(c("  ğŸ” æ­£åœ¨è¯†åˆ« API æœåŠ¡å•†...", C.CYAN))
    print()

    # 1. å‰ç¼€è¯†åˆ«
    provider = detect_provider_by_prefix(api_key)
    if provider:
        if provider["format"] == "anthropic":
            print(c(f"  âš ï¸  å·²è¯†åˆ«ä¸º Anthropic Claude å¯†é’¥ï¼Œæš‚ä¸æ”¯æŒå…¶åŸç”Ÿ API æ ¼å¼", C.YELLOW))
            print(c("     è¯·ä½¿ç”¨å…¼å®¹ OpenAI æ ¼å¼çš„è½¬å‘æœåŠ¡ï¼Œæˆ–æ‰‹åŠ¨æŒ‡å®š API åœ°å€", C.GRAY))
            print()
            safe_exit(1)
        if provider["format"] == "tencent_secret":
            print(c("  ğŸ§ å·²è¯†åˆ«ä¸ºè…¾è®¯äº‘ SecretId (AKID å¼€å¤´)", C.YELLOW))
            print()
            print(c("  âš ï¸  è¿™æ˜¯è…¾è®¯äº‘çš„ SecretIdï¼Œä¸èƒ½ç›´æ¥ç”¨äº API è°ƒç”¨", C.RED + C.BOLD))
            print(c("     è…¾è®¯äº‘æ··å…ƒçš„ OpenAI å…¼å®¹æ¨¡å¼éœ€è¦å•ç‹¬ç”Ÿæˆ API Keyã€‚", C.YELLOW))
            print()
            print(c("  ğŸ“‹ è·å– API Key æ­¥éª¤:", C.CYAN))
            print(c("     1. ç™»å½•è…¾è®¯äº‘æ§åˆ¶å°: https://console.cloud.tencent.com/hunyuan", C.WHITE))
            print(c("     2. è¿›å…¥ã€Œæ··å…ƒå¤§æ¨¡å‹ã€â†’ã€ŒAPIå¯†é’¥ç®¡ç†ã€", C.WHITE))
            print(c("     3. ç‚¹å‡»ã€Œåˆ›å»ºå¯†é’¥ã€ç”Ÿæˆ API Key (sk-* æ ¼å¼)", C.WHITE))
            print(c("     4. ç”¨æ–°ç”Ÿæˆçš„ API Key é‡æ–°æµ‹è¯•", C.WHITE))
            print()
            print(c("  ğŸ’¡ æç¤º: SecretId/SecretKey æ˜¯è…¾è®¯äº‘é€šç”¨é‰´æƒæ–¹å¼,", C.GRAY))
            print(c("     ä½†æ··å…ƒ OpenAI å…¼å®¹æ¥å£éœ€è¦ä¸“ç”¨ API Keyã€‚", C.GRAY))
            print()
            safe_exit(1)
        print_detected_provider(provider)
        return provider

    # 2. æ¢æµ‹
    if api_key.startswith("sk-"):
        print(c("  å¯†é’¥æ ¼å¼: sk-*** (é€šç”¨æ ¼å¼ï¼Œæ­£åœ¨é€ä¸€æ¢æµ‹æœåŠ¡å•†...)", C.GRAY))
        print()
        provider = probe_openai_providers(api_key)
        if provider:
            print()
            print_detected_provider(provider)
            return provider

    # 3. æœªçŸ¥æ ¼å¼ä¹Ÿå°è¯•æ¢æµ‹
    if not api_key.startswith("sk-"):
        print(c(f"  å¯†é’¥æ ¼å¼: {api_key[:6]}*** (éæ ‡å‡†æ ¼å¼ï¼Œå°è¯•æ¢æµ‹...)", C.YELLOW))
        print()
        provider = probe_openai_providers(api_key)
        if provider:
            print()
            print_detected_provider(provider)
            return provider

    # 4. è‡ªåŠ¨æ¢æµ‹å¤±è´¥ â†’ æä¾›æ‰‹åŠ¨é€‰æ‹©
    print()
    print(c("  âš ï¸  è‡ªåŠ¨æ¢æµ‹æœªèƒ½åŒ¹é…åˆ°æœåŠ¡å•†", C.YELLOW))
    print(c("     ä½ å¯ä»¥æ‰‹åŠ¨é€‰æ‹©ï¼Œæˆ–è¾“å…¥è‡ªå®šä¹‰åœ°å€:", C.GRAY))
    print()

    # åˆ—å‡ºå¸¸è§æœåŠ¡å•†ä¾›æ‰‹åŠ¨é€‰æ‹©
    manual_list = [
        {"name": "è…¾è®¯äº‘æ··å…ƒ",   "icon": "ğŸ§", "base_url": "https://api.hunyuan.cloud.tencent.com/v1"},
        {"name": "ç¡…åŸºæµåŠ¨",     "icon": "ğŸ”·", "base_url": "https://api.siliconflow.cn/v1"},
        {"name": "DeepSeek",    "icon": "ğŸ”¹", "base_url": "https://api.deepseek.com"},
        {"name": "é˜¿é‡Œäº‘ç™¾ç‚¼",   "icon": "â˜ï¸",  "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"},
        {"name": "æ™ºè°± AI",     "icon": "ğŸŸ£", "base_url": "https://open.bigmodel.cn/api/paas/v4"},
        {"name": "Moonshot",   "icon": "ğŸŒ™", "base_url": "https://api.moonshot.cn/v1"},
        {"name": "è®¯é£æ˜Ÿç«",     "icon": "âœ¨", "base_url": "https://spark-api-open.xf-yun.com/v1"},
        {"name": "ç«å±±å¼•æ“",     "icon": "ğŸŒ‹", "base_url": "https://ark.cn-beijing.volces.com/api/v3"},
        {"name": "OpenAI",     "icon": "ğŸŸ¢", "base_url": "https://api.openai.com/v1"},
        {"name": "Groq",       "icon": "ğŸŸ ", "base_url": "https://api.groq.com/openai/v1"},
    ]

    for i, p in enumerate(manual_list, 1):
        print(f"    {c(f'[{i:>2}]', C.CYAN)} {p['icon']} {c(p['name'], C.WHITE):<16s}  {c(p['base_url'], C.GRAY)}")
    print(f"    {c(f'[ 0]', C.CYAN)} {c('è¾“å…¥è‡ªå®šä¹‰åœ°å€', C.WHITE)}")
    print()

    try:
        choice = input(c("  è¯·é€‰æ‹© (è¾“å…¥ç¼–å·ï¼Œç›´æ¥å›è½¦é€€å‡º): ", C.BOLD)).strip()
    except (EOFError, KeyboardInterrupt):
        print()
        safe_exit(0)

    if not choice:
        print(c("\n  å·²é€€å‡ºã€‚\n", C.GRAY))
        safe_exit(0)

    try:
        idx = int(choice)
    except ValueError:
        # å¯èƒ½ç›´æ¥è¾“å…¥äº† URL
        if choice.startswith("http"):
            provider = {"name": "è‡ªå®šä¹‰", "icon": "ğŸ”§", "base_url": choice.rstrip("/"),
                         "format": FORMAT_OPENAI, "needs_proxy_cn": False}
            print_detected_provider(provider)
            return provider
        print(c("\n  âŒ è¾“å…¥æ— æ•ˆï¼Œé€€å‡ºã€‚\n", C.RED))
        safe_exit(1)

    if idx == 0:
        custom = input(c("  è¯·è¾“å…¥ API åœ°å€ (å¦‚ https://api.xxx.com/v1): ", C.BOLD)).strip()
        if not custom:
            safe_exit(0)
        provider = {"name": "è‡ªå®šä¹‰", "icon": "ğŸ”§", "base_url": custom.rstrip("/"),
                     "format": FORMAT_OPENAI, "needs_proxy_cn": False}
        print_detected_provider(provider)
        return provider
    elif 1 <= idx <= len(manual_list):
        p = manual_list[idx - 1]
        provider = {"name": p["name"], "icon": p["icon"], "base_url": p["base_url"],
                     "format": FORMAT_OPENAI, "needs_proxy_cn": False}
        print_detected_provider(provider)
        return provider
    else:
        print(c("\n  âŒ ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œé€€å‡ºã€‚\n", C.RED))
        safe_exit(1)


def print_detected_provider(provider):
    """æ‰“å°å·²è¯†åˆ«çš„æœåŠ¡å•†ä¿¡æ¯"""
    name = provider["name"]
    icon = provider["icon"]
    url = provider["base_url"]
    fmt = "Google Gemini API" if provider["format"] == FORMAT_GEMINI else "OpenAI å…¼å®¹"

    divider("â•")
    print(f"  âœ… å·²è¯†åˆ«æœåŠ¡å•†: {icon} {c(name, C.GREEN + C.BOLD)}")
    print(f"     API åœ°å€: {c(url, C.GRAY)}")
    print(f"     API æ ¼å¼: {c(fmt, C.CYAN)}")
    divider("â•")
    print()


def run_openai_diagnostic(provider, proxy_port=None, proxy_name=None):
    """OpenAI å…¼å®¹æœåŠ¡å•†çš„ç®€åŒ–ç½‘ç»œè¯Šæ–­"""
    print(c("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.CYAN))
    print(c("  â•‘", C.CYAN) + c("                    ğŸ” ç½‘ç»œè¿é€šæ€§æ£€æŸ¥                            ", C.BOLD) + c("â•‘", C.CYAN))
    print(c("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.CYAN))
    print()

    all_ok = True

    # ä»£ç†çŠ¶æ€
    if proxy_port:
        check_item("æœ¬åœ°ä»£ç†", "ok", f"http://127.0.0.1:{proxy_port} ({proxy_name})")
    else:
        if provider.get("needs_proxy_cn"):
            check_item("æœ¬åœ°ä»£ç†", "warn", "æœªæ£€æµ‹åˆ°ä»£ç†",
                       f"åœ¨ä¸­å›½å¤§é™†è®¿é—® {provider['name']} å¯èƒ½éœ€è¦ä»£ç†")
        else:
            check_item("ä»£ç†", "ok", "æ— éœ€ä»£ç† (å›½å†…å¯ç›´è¿)")

    # è¿é€šæ€§
    base_url = provider["base_url"]
    try:
        t0 = time.time()
        resp = _session.get(f"{base_url}/models",
                            headers={"Authorization": "Bearer __test__"},
                            timeout=10)
        latency = int((time.time() - t0) * 1000)
        if resp.status_code in (200, 401, 403):
            check_item(f"{provider['name']} è¿é€šæ€§", "ok",
                       f"HTTP {resp.status_code}, å»¶è¿Ÿ {latency}ms")
        else:
            check_item(f"{provider['name']} è¿é€šæ€§", "warn",
                       f"HTTP {resp.status_code}, å»¶è¿Ÿ {latency}ms")
    except Exception as e:
        check_item(f"{provider['name']} è¿é€šæ€§", "fail", str(e)[:60],
                   "æ— æ³•è¿æ¥åˆ°æœåŠ¡å•†ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ä»£ç†é…ç½®")
        all_ok = False

    print()
    if all_ok:
        print(c("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.GREEN))
        print(c("  â•‘  âœ… ç½‘ç»œæ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹æµ‹è¯•                                    â•‘", C.GREEN))
        print(c("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.GREEN))
    else:
        print(c("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.YELLOW))
        print(c("  â•‘  âš ï¸  ç½‘ç»œå¯èƒ½å­˜åœ¨é—®é¢˜                                         â•‘", C.YELLOW))
        print(c("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.YELLOW))
        print()
        choice = input(c("  æ˜¯å¦ä»è¦ç»§ç»­æµ‹è¯•? (Y/n): ", C.BOLD)).strip().lower()
        if choice == "n":
            safe_exit(0)
    print()


# â”€â”€â”€ ç½‘ç»œä¸ä»£ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

OFFICIAL_URL = "https://generativelanguage.googleapis.com/v1beta"

_session = requests.Session()
_session.verify = False

def detect_proxy():
    """è‡ªåŠ¨æ£€æµ‹æœ¬åœ°ä»£ç†ç«¯å£"""
    for port, name in [(7890,"Clash"), (7891,"Clash"), (10809,"V2RayN"), (10808,"V2RayN"),
                       (1080,"SS/SSR"), (1081,"SS/SSR"), (10801,"V2Ray"), (33210,"Clash Verge"), (8080,"HTTP Proxy")]:
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            s.settimeout(0.3)
            if s.connect_ex(("127.0.0.1", port)) == 0:
                s.close()
                return port, name
            s.close()
        except Exception:
            pass
    return None, None

def check_item(label, status, detail="", hint=""):
    """æ‰“å°ä¸€é¡¹è¯Šæ–­ç»“æœ"""
    if status == "ok":
        icon = c(" âœ“ ", C.GREEN + C.BOLD)
    elif status == "warn":
        icon = c(" âš  ", C.YELLOW + C.BOLD)
    elif status == "fail":
        icon = c(" âœ— ", C.RED + C.BOLD)
    else:
        icon = c(" â— ", C.GRAY)

    print(f"  {icon} {c(label, C.WHITE)}", end="")
    if detail:
        print(f"  {c(detail, C.GRAY)}", end="")
    print()
    if hint:
        print(f"        {c(hint, C.YELLOW)}")

def run_network_diagnostic(base_url=None):
    """è¿è¡Œå…¨é¢ç½‘ç»œè¯Šæ–­ï¼Œé…ç½®ä»£ç†ï¼Œè¿”å› (base_url, diagnostics_passed)ã€‚
    è¯Šæ–­ç»“æœç›´æ¥æ‰“å°ï¼Œç”¨æˆ·å¯ä»¥ä¸€çœ¼å®šä½é—®é¢˜ã€‚"""

    print(c("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.CYAN))
    print(c("  â•‘", C.CYAN) + c("                    ğŸ” ç½‘ç»œç¯å¢ƒè¯Šæ–­                            ", C.BOLD) + c("â•‘", C.CYAN))
    print(c("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.CYAN))
    print()

    all_ok = True
    proxy_url = None
    proxy_name = None

    # â”€â”€ 1. æœ¬åœ°ä»£ç†æ£€æµ‹ â”€â”€
    port, name = detect_proxy()
    if port:
        proxy_url = f"http://127.0.0.1:{port}"
        proxy_name = name
        _session.proxies = {"http": proxy_url, "https": proxy_url}
        _session.trust_env = False
        check_item("æœ¬åœ°ä»£ç†", "ok", f"{proxy_url} ({name})")
    else:
        sys_proxies = urllib.request.getproxies()
        if sys_proxies:
            _session.trust_env = True
            proxy_info = ", ".join(f"{k}={v}" for k, v in sys_proxies.items())
            check_item("ç³»ç»Ÿä»£ç†", "ok", proxy_info)
        else:
            check_item("æœ¬åœ°ä»£ç†", "warn", "æœªæ£€æµ‹åˆ°ä»£ç†è½¯ä»¶ (Clash/V2Ray ç­‰)",
                       "å¦‚æœä½ åœ¨ä¸­å›½å¤§é™†ï¼Œéœ€è¦ä»£ç†æ‰èƒ½è®¿é—® Google API")
            all_ok = False

    # â”€â”€ 2. DNS è§£æ â”€â”€
    try:
        ip = socket.gethostbyname("generativelanguage.googleapis.com")
        check_item("DNS è§£æ", "ok", f"generativelanguage.googleapis.com â†’ {ip}")
    except socket.gaierror:
        check_item("DNS è§£æ", "fail", "æ— æ³•è§£æ generativelanguage.googleapis.com",
                   "DNS è¢«æ±¡æŸ“æˆ–æ— ç½‘ç»œï¼Œå°è¯•æ›´æ¢ DNS ä¸º 8.8.8.8 æˆ– 1.1.1.1")
        all_ok = False
    except Exception as e:
        check_item("DNS è§£æ", "fail", str(e)[:60])
        all_ok = False

    # â”€â”€ 3. ç½‘ç»œè¿é€šæ€§ï¼ˆé€šè¿‡ä»£ç†ï¼‰ â”€â”€
    try:
        t0 = time.time()
        resp = _session.get("https://generativelanguage.googleapis.com/", timeout=10)
        latency = int((time.time() - t0) * 1000)
        # 404 is expected for root URL, anything except connection error means connected
        check_item("Google è¿é€šæ€§", "ok", f"HTTP {resp.status_code}, å»¶è¿Ÿ {latency}ms")
    except requests.exceptions.ProxyError as e:
        check_item("Google è¿é€šæ€§", "fail", "ä»£ç†è¿æ¥å¤±è´¥",
                   f"ä»£ç† {proxy_url or 'ç³»ç»Ÿä»£ç†'} æ— æ³•è½¬å‘è¯·æ±‚ï¼Œè¯·æ£€æŸ¥ä»£ç†æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        all_ok = False
    except requests.exceptions.SSLError as e:
        check_item("Google è¿é€šæ€§", "fail", "SSL é”™è¯¯",
                   "SSL è¯ä¹¦éªŒè¯å¤±è´¥ï¼Œå¯èƒ½æ˜¯ä»£ç†é…ç½®é—®é¢˜æˆ–ç½‘ç»œåŠ«æŒ")
        all_ok = False
    except requests.exceptions.ConnectionError as e:
        err_short = str(e)[:80]
        check_item("Google è¿é€šæ€§", "fail", f"è¿æ¥å¤±è´¥: {err_short}",
                   "æ— æ³•è¿æ¥åˆ° Google æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’Œä»£ç†é…ç½®")
        all_ok = False
    except requests.exceptions.Timeout:
        check_item("Google è¿é€šæ€§", "fail", "è¿æ¥è¶…æ—¶ (10s)",
                   "ç½‘ç»œè¿‡æ…¢æˆ–è¢«é˜»æ–­ï¼Œè¯·æ£€æŸ¥ä»£ç†èŠ‚ç‚¹æ˜¯å¦å¯ç”¨")
        all_ok = False
    except Exception as e:
        check_item("Google è¿é€šæ€§", "warn", str(e)[:60])

    # â”€â”€ 4. å‡ºå£ IP & åœ°åŒºæ£€æµ‹ â”€â”€
    exit_ip = None
    ip_region = None
    try:
        resp = _session.get("https://ipinfo.io/json", timeout=8)
        if resp.status_code == 200:
            ip_data = resp.json()
            exit_ip = ip_data.get("ip", "æœªçŸ¥")
            ip_region = ip_data.get("country", "")
            ip_city = ip_data.get("city", "")
            ip_org = ip_data.get("org", "")
            location_str = f"{exit_ip} ({ip_city}, {ip_region}) {ip_org}"

            # æ£€æŸ¥æ˜¯å¦åœ¨ä¸å—æ”¯æŒçš„åœ°åŒº
            unsupported = {"CN", "HK", "RU", "BY", "CU", "IR", "KP", "SY"}
            if ip_region in unsupported:
                region_names = {"CN": "ä¸­å›½å¤§é™†", "HK": "é¦™æ¸¯", "RU": "ä¿„ç½—æ–¯", "BY": "ç™½ä¿„ç½—æ–¯",
                                "CU": "å¤å·´", "IR": "ä¼Šæœ—", "KP": "æœé²œ", "SY": "å™åˆ©äºš"}
                rname = region_names.get(ip_region, ip_region)
                check_item("å‡ºå£ IP/åœ°åŒº", "fail", location_str,
                           f"å½“å‰å‡ºå£åœ°åŒº [{rname}] ä¸å— Gemini API æ”¯æŒï¼è¯·åˆ‡æ¢åˆ° ç¾å›½/æ—¥æœ¬/è‹±å›½/æ–°åŠ å¡ ç­‰èŠ‚ç‚¹")
                all_ok = False
            else:
                check_item("å‡ºå£ IP/åœ°åŒº", "ok", location_str)
        else:
            check_item("å‡ºå£ IP/åœ°åŒº", "warn", f"æŸ¥è¯¢å¤±è´¥ (HTTP {resp.status_code})")
    except Exception:
        # å¤‡ç”¨ IP æ£€æµ‹
        try:
            resp = _session.get("https://httpbin.org/ip", timeout=8)
            exit_ip = resp.json().get("origin", "æœªçŸ¥")
            check_item("å‡ºå£ IP", "ok", exit_ip + " (åœ°åŒºæœªçŸ¥)")
        except Exception:
            check_item("å‡ºå£ IP/åœ°åŒº", "warn", "æ£€æµ‹å¤±è´¥ï¼Œè·³è¿‡")

    # â”€â”€ 5. API ç«¯ç‚¹å¯è¾¾æ€§ â”€â”€
    if not base_url:
        base_url = OFFICIAL_URL

    try:
        resp = _session.get(f"{base_url}/models?key=__TEST__&pageSize=1", timeout=10)
        if resp.status_code == 400:
            err_msg = resp.json().get("error", {}).get("message", "")
            if "location" in err_msg.lower():
                check_item("API ç«¯ç‚¹", "fail", f"{base_url}",
                           "API å¯è¾¾ä½†åœ°åŒºè¢«é™åˆ¶ï¼Œè¯·åˆ‡æ¢ä»£ç†èŠ‚ç‚¹åˆ°æ”¯æŒçš„åœ°åŒº")
                all_ok = False
            elif "api key" in err_msg.lower():
                check_item("API ç«¯ç‚¹", "ok", f"{base_url} (ç«¯ç‚¹æ­£å¸¸)")
            else:
                check_item("API ç«¯ç‚¹", "warn", f"HTTP 400: {err_msg[:50]}")
        elif resp.status_code in (401, 403):
            check_item("API ç«¯ç‚¹", "ok", f"{base_url} (ç«¯ç‚¹æ­£å¸¸ï¼Œå¾…éªŒè¯å¯†é’¥)")
        else:
            check_item("API ç«¯ç‚¹", "ok", f"{base_url} (HTTP {resp.status_code})")
    except Exception as e:
        check_item("API ç«¯ç‚¹", "fail", str(e)[:60],
                   f"æ— æ³•è®¿é—® {base_url}ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–å°è¯•ä½¿ç”¨åå‘ä»£ç†åœ°å€")
        all_ok = False

    # â”€â”€ è¯Šæ–­æ€»ç»“ â”€â”€
    print()
    if all_ok:
        print(c("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.GREEN))
        print(c("  â•‘  âœ… ç½‘ç»œç¯å¢ƒæ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹æµ‹è¯•                                â•‘", C.GREEN))
        print(c("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.GREEN))
    else:
        print(c("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.YELLOW))
        print(c("  â•‘  âš ï¸  æ£€æµ‹åˆ°ç½‘ç»œé—®é¢˜ (ä¸Šæ–¹æ ‡ âœ— çš„é¡¹ç›®)                          â•‘", C.YELLOW))
        print(c("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£", C.YELLOW))
        # æä¾›é’ˆå¯¹æ€§ä¿®å¤å»ºè®®
        if not port and not urllib.request.getproxies():
            print(c("  â•‘  â†’ æœªæ£€æµ‹åˆ°ä»£ç†: å®‰è£…å¹¶å¼€å¯ Clash/V2Ray ç­‰ä»£ç†è½¯ä»¶          â•‘", C.YELLOW))
        if ip_region and ip_region in {"CN", "HK", "RU", "BY", "CU", "IR", "KP", "SY"}:
            print(c("  â•‘  â†’ åœ°åŒºå—é™: åœ¨ä»£ç†è½¯ä»¶ä¸­åˆ‡æ¢åˆ° ç¾å›½/æ—¥æœ¬/è‹±å›½ ç­‰èŠ‚ç‚¹       â•‘", C.YELLOW))
            print(c("  â•‘    æˆ–ä½¿ç”¨åå‘ä»£ç†åœ°å€ (è¿è¡Œæ—¶ä¼ å…¥ç¬¬äºŒä¸ªå‚æ•°)                 â•‘", C.YELLOW))
        print(c("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.YELLOW))
        print()
        choice = input(c("  æ˜¯å¦ä»è¦ç»§ç»­æµ‹è¯•? (Y/n): ", C.BOLD)).strip().lower()
        if choice == "n":
            print()
            safe_exit(0)

    print()
    return base_url

def api_request(url, data=None):
    """å‘é€ API è¯·æ±‚"""
    try:
        if data is not None:
            resp = _session.post(url, json=data, timeout=30)
        else:
            resp = _session.get(url, timeout=30)
        return resp.status_code, resp.json() if resp.text else {}
    except requests.exceptions.ProxyError as e:
        raise ConnectionError(f"ä»£ç†è¿æ¥å¤±è´¥: {e}")
    except requests.exceptions.ConnectionError as e:
        raise ConnectionError(f"ç½‘ç»œè¿æ¥å¤±è´¥: {e}")
    except requests.exceptions.Timeout:
        raise ConnectionError("è¯·æ±‚è¶…æ—¶")
    except requests.exceptions.JSONDecodeError:
        return resp.status_code, {}
    except Exception as e:
        raise ConnectionError(f"è¯·æ±‚å¼‚å¸¸: {e}")

# â”€â”€â”€ è·å–ä¸æµ‹è¯•æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fetch_models(base_url, api_key):
    """è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹"""
    models = []
    page_token = ""
    for _ in range(10):
        url = f"{base_url}/models?key={api_key}&pageSize=1000"
        if page_token:
            url += f"&pageToken={page_token}"
        status, data = api_request(url)
        if status != 200:
            err_msg = data.get("error", {}).get("message", f"HTTP {status}")
            if status in (401, 403):
                raise PermissionError(f"å¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ: {err_msg}")
            elif status == 429:
                raise ConnectionError(f"è¯·æ±‚é¢‘ç‡è¶…é™: {err_msg}")
            else:
                raise RuntimeError(f"è¯·æ±‚å¤±è´¥ ({status}): {err_msg}")
        models.extend(data.get("models", []))
        page_token = data.get("nextPageToken", "")
        if not page_token:
            break
    return models

def test_model(base_url, api_key, model):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹ï¼Œè¿”å› (True/False/None, message)"""
    methods = model.get("supportedGenerationMethods", [])
    name = model.get("name", "")
    try:
        if "generateContent" in methods:
            url = f"{base_url}/{name}:generateContent?key={api_key}"
            payload = {"contents": [{"parts": [{"text": "Say OK"}]}],
                       "generationConfig": {"maxOutputTokens": 10}}
            status, data = api_request(url, data=payload)
            if status == 200:
                try:
                    txt = data["candidates"][0]["content"]["parts"][0]["text"].strip()[:30]
                except (KeyError, IndexError):
                    txt = "(ç©ºå“åº”)"
                return True, txt
            else:
                return False, data.get("error", {}).get("message", f"HTTP {status}")[:50]
        elif "embedContent" in methods:
            url = f"{base_url}/{name}:embedContent?key={api_key}"
            status, data = api_request(url, data={"content": {"parts": [{"text": "Hello"}]}})
            if status == 200:
                dim = len(data.get("embedding", {}).get("values", []))
                return True, f"ç»´åº¦ {dim}"
            else:
                return False, data.get("error", {}).get("message", f"HTTP {status}")[:50]
        elif "embedText" in methods:
            url = f"{base_url}/{name}:embedText?key={api_key}"
            status, data = api_request(url, data={"text": "Hello"})
            if status == 200:
                dim = len(data.get("embedding", {}).get("value", []))
                return True, f"ç»´åº¦ {dim}"
            else:
                return False, data.get("error", {}).get("message", f"HTTP {status}")[:50]
        else:
            return None, "æ— å¯æµ‹è¯•æ¥å£"
    except Exception as e:
        return False, str(e)[:50]

# â”€â”€â”€ å·²çŸ¥æ¨¡å‹å‚æ•° & é”™è¯¯ç¿»è¯‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# å½“ API ä¸è¿”å› token é™é¢æ—¶ï¼Œä»æ­¤è¡¨ä¸­è¡¥å…¨
KNOWN_MODEL_SPECS = {
    # DeepSeek
    "deepseek-chat":         {"input": 65_536,   "output": 8_192},
    "deepseek-reasoner":     {"input": 65_536,   "output": 8_192},
    "deepseek-coder":        {"input": 65_536,   "output": 8_192},
    "deepseek-v3":           {"input": 65_536,   "output": 8_192},
    "deepseek-r1":           {"input": 65_536,   "output": 8_192},
    # OpenAI
    "gpt-4o":                {"input": 128_000,  "output": 16_384},
    "gpt-4o-mini":           {"input": 128_000,  "output": 16_384},
    "gpt-4-turbo":           {"input": 128_000,  "output": 4_096},
    "gpt-4":                 {"input": 8_192,    "output": 8_192},
    "gpt-3.5-turbo":         {"input": 16_385,   "output": 4_096},
    "o1":                    {"input": 200_000,  "output": 100_000},
    "o1-mini":               {"input": 128_000,  "output": 65_536},
    "o1-preview":            {"input": 128_000,  "output": 32_768},
    "o3-mini":               {"input": 200_000,  "output": 100_000},
    # Qwen (é€šä¹‰åƒé—®)
    "qwen-turbo":            {"input": 131_072,  "output": 8_192},
    "qwen-plus":             {"input": 131_072,  "output": 8_192},
    "qwen-max":              {"input": 32_768,   "output": 8_192},
    "qwen-long":             {"input": 1_000_000,"output": 8_192},
    "qwen2.5-72b-instruct":  {"input": 131_072,  "output": 8_192},
    "qwen2.5-32b-instruct":  {"input": 131_072,  "output": 8_192},
    "qwen2.5-14b-instruct":  {"input": 131_072,  "output": 8_192},
    "qwen2.5-7b-instruct":   {"input": 131_072,  "output": 8_192},
    # Moonshot (Kimi)
    "moonshot-v1-8k":        {"input": 8_192,    "output": 4_096},
    "moonshot-v1-32k":       {"input": 32_768,   "output": 16_384},
    "moonshot-v1-128k":      {"input": 131_072,  "output": 65_536},
    # GLM (æ™ºè°±)
    "glm-4":                 {"input": 128_000,  "output": 4_096},
    "glm-4-flash":           {"input": 128_000,  "output": 4_096},
    "glm-4-plus":            {"input": 128_000,  "output": 4_096},
    "glm-4-long":            {"input": 1_000_000,"output": 4_096},
    # Yi (é›¶ä¸€ä¸‡ç‰©)
    "yi-large":              {"input": 32_768,   "output": 4_096},
    "yi-medium":             {"input": 16_384,   "output": 4_096},
    "yi-spark":              {"input": 16_384,   "output": 4_096},
    # Claude (via OpenAI å…¼å®¹è½¬å‘)
    "claude-3-opus":         {"input": 200_000,  "output": 4_096},
    "claude-3-sonnet":       {"input": 200_000,  "output": 4_096},
    "claude-3-haiku":        {"input": 200_000,  "output": 4_096},
    "claude-3.5-sonnet":     {"input": 200_000,  "output": 8_192},
    # Llama
    "meta-llama/Meta-Llama-3.1-405B-Instruct": {"input": 131_072, "output": 4_096},
    "meta-llama/Meta-Llama-3.1-70B-Instruct":  {"input": 131_072, "output": 4_096},
    "meta-llama/Meta-Llama-3.1-8B-Instruct":   {"input": 131_072, "output": 4_096},
    # Mistral
    "mistral-large-latest":  {"input": 128_000,  "output": 4_096},
    "mistral-small-latest":  {"input": 128_000,  "output": 4_096},
    # è…¾è®¯äº‘æ··å…ƒ
    "hunyuan-pro":           {"input": 32_000,   "output": 4_096},
    "hunyuan-standard":      {"input": 32_000,   "output": 4_096},
    "hunyuan-lite":          {"input": 32_000,   "output": 4_096},
    "hunyuan-turbo":         {"input": 32_000,   "output": 4_096},
    "hunyuan-large":         {"input": 32_000,   "output": 4_096},
    "hunyuan-code":          {"input": 32_000,   "output": 4_096},
    "hunyuan-role":          {"input": 32_000,   "output": 4_096},
    "hunyuan-functioncall":  {"input": 32_000,   "output": 4_096},
    "hunyuan-vision":        {"input": 32_000,   "output": 4_096},
    # è®¯é£æ˜Ÿç«
    "generalv3.5":           {"input": 128_000,  "output": 4_096},
    "generalv3":             {"input": 8_192,    "output": 4_096},
    "4.0Ultra":              {"input": 128_000,  "output": 8_192},
}


def fill_model_specs(model):
    """ç”¨å·²çŸ¥å‚æ•°è¡¥å…¨ API æœªè¿”å›çš„ token é™é¢"""
    model_id = model.get("_model_id") or model.get("name", "").replace("models/", "")
    if model.get("inputTokenLimit") and model.get("outputTokenLimit"):
        return  # å·²æœ‰ï¼Œæ— éœ€è¡¥å…¨

    # ç²¾ç¡®åŒ¹é…
    specs = KNOWN_MODEL_SPECS.get(model_id)
    if not specs:
        # å‰ç¼€æ¨¡ç³ŠåŒ¹é… (å¦‚ deepseek-chat-v2 åŒ¹é… deepseek-chat)
        mid = model_id.lower()
        for key, val in KNOWN_MODEL_SPECS.items():
            if mid.startswith(key.lower()) or key.lower().startswith(mid):
                specs = val
                break
    if specs:
        if not model.get("inputTokenLimit"):
            model["inputTokenLimit"] = specs["input"]
        if not model.get("outputTokenLimit"):
            model["outputTokenLimit"] = specs["output"]


# OpenAI å…¼å®¹ API å¸¸è§é”™è¯¯ç  â†’ ä¸­æ–‡æç¤º
ERROR_TRANSLATIONS = {
    # HTTP çŠ¶æ€ç çº§åˆ«
    400: "è¯·æ±‚å‚æ•°é”™è¯¯",
    401: "å¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ",
    402: "è´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·å……å€¼",
    403: "æ²¡æœ‰æƒé™è®¿é—®æ­¤æ¨¡å‹",
    404: "æ¨¡å‹ä¸å­˜åœ¨æˆ–å·²ä¸‹çº¿",
    408: "è¯·æ±‚è¶…æ—¶",
    413: "è¯·æ±‚å†…å®¹è¿‡é•¿ (è¶…å‡º Token ä¸Šé™)",
    422: "è¯·æ±‚æ ¼å¼é”™è¯¯ (ä¸å¯å¤„ç†)",
    429: "è¯·æ±‚å¤ªé¢‘ç¹ï¼Œå·²è§¦å‘é€Ÿç‡é™åˆ¶",
    500: "æœåŠ¡å•†å†…éƒ¨é”™è¯¯",
    502: "æœåŠ¡å•†ç½‘å…³é”™è¯¯",
    503: "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ (å¯èƒ½åœ¨ç»´æŠ¤ä¸­)",
    504: "æœåŠ¡å•†ç½‘å…³è¶…æ—¶",
    529: "æœåŠ¡è¿‡è½½ï¼Œè¯·ç¨åé‡è¯•",
}

# å…³é”®è¯ â†’ ä¸­æ–‡ç¿»è¯‘ (åŒ¹é…è‹±æ–‡é”™è¯¯ä¿¡æ¯)
ERROR_KEYWORD_MAP = [
    ("insufficient balance",    "è´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·å‰å¾€å¹³å°å……å€¼"),
    ("insufficient_balance",    "è´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·å‰å¾€å¹³å°å……å€¼"),
    ("insufficient quota",      "é…é¢ä¸è¶³ï¼Œè¯·å‰å¾€å¹³å°å……å€¼æˆ–å‡çº§å¥—é¤"),
    ("quota exceeded",          "é…é¢å·²è€—å°½"),
    ("rate limit",              "è¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·é™ä½è°ƒç”¨é¢‘ç‡"),
    ("rate_limit_exceeded",     "è¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·é™ä½è°ƒç”¨é¢‘ç‡"),
    ("invalid api key",         "å¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ˜¯å¦æ­£ç¡®å¤åˆ¶"),
    ("invalid_api_key",         "å¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ˜¯å¦æ­£ç¡®å¤åˆ¶"),
    ("invalid api-key",         "å¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ˜¯å¦æ­£ç¡®å¤åˆ¶"),
    ("authentication",          "è®¤è¯å¤±è´¥ï¼Œå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ"),
    ("unauthorized",            "æœªæˆæƒï¼Œå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ"),
    ("permission denied",       "æ²¡æœ‰æƒé™ï¼Œå¯èƒ½æœªå¼€é€šæ­¤æ¨¡å‹"),
    ("model not found",         "æ¨¡å‹ä¸å­˜åœ¨æˆ–æœªå¼€é€š"),
    ("model_not_found",         "æ¨¡å‹ä¸å­˜åœ¨æˆ–æœªå¼€é€š"),
    ("not found",               "èµ„æºä¸å­˜åœ¨"),
    ("content filter",          "å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨æ‹¦æˆª"),
    ("content_filter",          "å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨æ‹¦æˆª"),
    ("context length exceeded",  "è¾“å…¥å†…å®¹è¶…å‡ºä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶"),
    ("context_length_exceeded",  "è¾“å…¥å†…å®¹è¶…å‡ºä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶"),
    ("server error",            "æœåŠ¡å•†å†…éƒ¨é”™è¯¯"),
    ("internal error",          "æœåŠ¡å•†å†…éƒ¨é”™è¯¯"),
    ("overloaded",              "æœåŠ¡è¿‡è½½ï¼Œè¯·ç¨åé‡è¯•"),
    ("timeout",                 "è¯·æ±‚è¶…æ—¶"),
    ("billing",                 "è®¡è´¹é—®é¢˜ï¼Œè¯·æ£€æŸ¥è´¦æˆ·çŠ¶æ€"),
    ("payment required",        "éœ€è¦ä»˜è´¹ï¼Œè¯·å…ˆå……å€¼"),
    ("account deactivated",     "è´¦æˆ·å·²åœç”¨"),
    ("deactivated",             "è´¦æˆ·å·²åœç”¨"),
    ("expired",                 "å¯†é’¥å·²è¿‡æœŸï¼Œè¯·é‡æ–°ç”Ÿæˆ"),
]


def translate_error(status_code, error_msg):
    """å°† API é”™è¯¯ä¿¡æ¯ç¿»è¯‘æˆä¸­æ–‡ï¼Œè¿”å› (ä¸­æ–‡æ‘˜è¦, åŸå§‹ä¿¡æ¯)"""
    msg_lower = (error_msg or "").lower()

    # 1. å…³é”®è¯åŒ¹é…
    for keyword, translation in ERROR_KEYWORD_MAP:
        if keyword in msg_lower:
            return translation

    # 2. çŠ¶æ€ç åŒ¹é…
    if status_code in ERROR_TRANSLATIONS:
        return ERROR_TRANSLATIONS[status_code]

    # 3. æ— æ³•ç¿»è¯‘ï¼Œä¿ç•™åŸæ–‡ä½†åŠ ä¸­æ–‡çŠ¶æ€ç æç¤º
    status_hint = ERROR_TRANSLATIONS.get(status_code, f"HTTP {status_code}")
    if error_msg:
        return f"{status_hint}: {error_msg[:60]}"
    return status_hint


def query_openai_balance(base_url, api_key, provider_name):
    """å°è¯•æŸ¥è¯¢ OpenAI å…¼å®¹æœåŠ¡å•†çš„è´¦æˆ·ä½™é¢/ä½¿ç”¨é‡ä¿¡æ¯"""
    balance_info = {}

    # ä¸åŒæœåŠ¡å•†æœ‰ä¸åŒçš„ä½™é¢æŸ¥è¯¢ç«¯ç‚¹
    balance_endpoints = [
        # SiliconFlow
        {"path": "/user/info",       "type": "siliconflow"},
        # DeepSeek
        {"path": "/user/balance",    "type": "deepseek"},
        # é€šç”¨ OpenAI dashboard
        {"path": "/dashboard/billing/credit_grants", "type": "openai_credit"},
        {"path": "/dashboard/billing/usage",         "type": "openai_usage"},
    ]

    headers = {"Authorization": f"Bearer {api_key}"}

    for ep in balance_endpoints:
        # æ„å»º URL: ç§»é™¤ /v1 åç¼€å†æ‹¼æ¥
        url_base = base_url.rstrip("/")
        if url_base.endswith("/v1"):
            url_base = url_base[:-3]
        elif url_base.endswith("/v4"):
            url_base = url_base[:-3]

        url = f"{url_base}{ep['path']}"
        try:
            resp = _session.get(url, headers=headers, timeout=8)
            if resp.status_code == 200:
                data = resp.json()
                ep_type = ep["type"]

                if ep_type == "siliconflow":
                    # SiliconFlow: {"data": {"balance": "1.23", ...}}
                    bal = data.get("data", {}).get("balance")
                    if bal is not None:
                        balance_info["balance"] = float(bal)
                        balance_info["currency"] = "CNY"
                        balance_info["source"] = "SiliconFlow"
                        break

                elif ep_type == "deepseek":
                    # DeepSeek: {"balance_infos": [{"currency":"CNY","total_balance":"5.00",...}]}
                    infos = data.get("balance_infos", [])
                    if not infos and data.get("is_available") is not None:
                        balance_info["available"] = data.get("is_available", False)
                        balance_info["source"] = "DeepSeek"
                        break
                    for bi in infos:
                        balance_info["balance"] = float(bi.get("total_balance", 0))
                        balance_info["currency"] = bi.get("currency", "CNY")
                        balance_info["source"] = "DeepSeek"
                        break
                    if balance_info:
                        break

                elif ep_type == "openai_credit":
                    total = data.get("total_granted", 0)
                    used = data.get("total_used", 0)
                    balance_info["balance"] = total - used
                    balance_info["total_granted"] = total
                    balance_info["total_used"] = used
                    balance_info["currency"] = "USD"
                    balance_info["source"] = "OpenAI"
                    break

        except Exception:
            continue

    return balance_info


def print_account_diagnosis(provider, api_key, base_url, balance_info, models, test_results):
    """æ‰“å°è´¦æˆ·è¯Šæ–­ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½™é¢ã€å¯†é’¥çŠ¶æ€ã€å¸¸è§é—®é¢˜æç¤º"""
    print()
    divider("â•")
    print(c(f"  ğŸ’³ è´¦æˆ·çŠ¶æ€è¯Šæ–­ ({provider['icon']} {provider['name']})", C.BOLD))
    divider("â•")
    print()

    # ä½™é¢ä¿¡æ¯
    if balance_info:
        bal = balance_info.get("balance")
        currency = balance_info.get("currency", "")
        currency_symbol = {"CNY": "Â¥", "USD": "$", "EUR": "â‚¬"}.get(currency, currency + " ")

        if bal is not None:
            if bal <= 0:
                check_item("è´¦æˆ·ä½™é¢", "fail", f"{currency_symbol}{bal:.2f}",
                           "ä½™é¢ä¸ºé›¶ï¼è¯·å‰å¾€å¹³å°å……å€¼åå†æµ‹è¯•")
            elif bal < 1:
                check_item("è´¦æˆ·ä½™é¢", "warn", f"{currency_symbol}{bal:.2f}",
                           "ä½™é¢è¾ƒä½ï¼Œå»ºè®®åŠæ—¶å……å€¼")
            else:
                check_item("è´¦æˆ·ä½™é¢", "ok", f"{currency_symbol}{bal:.2f}")
        elif balance_info.get("available") is not None:
            if balance_info["available"]:
                check_item("è´¦æˆ·çŠ¶æ€", "ok", "å¯ç”¨")
            else:
                check_item("è´¦æˆ·çŠ¶æ€", "fail", "ä¸å¯ç”¨", "è¯·æ£€æŸ¥è´¦æˆ·ä½™é¢æˆ–çŠ¶æ€")
    else:
        check_item("è´¦æˆ·ä½™é¢", "info", "æ— æ³•æŸ¥è¯¢ (è¯¥å¹³å°å¯èƒ½ä¸æ”¯æŒä½™é¢æŸ¥è¯¢æ¥å£)")

    # æ¨¡å‹æµ‹è¯•ç»Ÿè®¡
    if test_results:
        ok_count = sum(1 for s, _ in test_results.values() if s is True)
        fail_count = sum(1 for s, _ in test_results.values() if s is False)
        total = ok_count + fail_count

        if total > 0:
            if ok_count == 0:
                check_item("æ¨¡å‹å¯ç”¨æ€§", "fail", f"0/{total} å¯ç”¨",
                           "æ‰€æœ‰æ¨¡å‹å‡ä¸å¯ç”¨ï¼Œé€šå¸¸æ˜¯ä½™é¢ä¸è¶³æˆ–å¯†é’¥æƒé™é—®é¢˜")
            elif fail_count > ok_count:
                check_item("æ¨¡å‹å¯ç”¨æ€§", "warn", f"{ok_count}/{total} å¯ç”¨",
                           "è¾ƒå¤šæ¨¡å‹ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯å¥—é¤é™åˆ¶æˆ–æ¨¡å‹æœªå¼€é€š")
            else:
                check_item("æ¨¡å‹å¯ç”¨æ€§", "ok", f"{ok_count}/{total} å¯ç”¨")

        # åˆ†æå¸¸è§é”™è¯¯åŸå› 
        error_reasons = {}
        for name, (ok, msg) in test_results.items():
            if ok is False and msg:
                reason = translate_error(0, msg)
                error_reasons.setdefault(reason, []).append(name)

        if error_reasons:
            print()
            print(c("  ğŸ“‹ é”™è¯¯åŸå› åˆ†æ:", C.BOLD))
            for reason, model_names in sorted(error_reasons.items(),
                                               key=lambda x: -len(x[1])):
                count = len(model_names)
                examples = ", ".join(n.replace("models/", "") for n in model_names[:3])
                if count > 3:
                    examples += f" ç­‰ {count} ä¸ªæ¨¡å‹"
                print(f"     {c('â€¢', C.YELLOW)} {c(reason, C.WHITE)} â†’ {c(examples, C.GRAY)}")

    print()


# â”€â”€â”€ OpenAI å…¼å®¹ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def openai_api_request(url, api_key, data=None):
    """å‘é€ OpenAI å…¼å®¹æ ¼å¼çš„ API è¯·æ±‚"""
    headers = {"Authorization": f"Bearer {api_key}"}
    try:
        if data is not None:
            headers["Content-Type"] = "application/json"
            resp = _session.post(url, json=data, headers=headers, timeout=30)
        else:
            resp = _session.get(url, headers=headers, timeout=30)
        return resp.status_code, resp.json() if resp.text else {}, resp.headers
    except requests.exceptions.ProxyError as e:
        raise ConnectionError(f"ä»£ç†è¿æ¥å¤±è´¥: {e}")
    except requests.exceptions.ConnectionError as e:
        raise ConnectionError(f"ç½‘ç»œè¿æ¥å¤±è´¥: {e}")
    except requests.exceptions.Timeout:
        raise ConnectionError("è¯·æ±‚è¶…æ—¶")
    except requests.exceptions.JSONDecodeError:
        return resp.status_code, {}, resp.headers
    except Exception as e:
        raise ConnectionError(f"è¯·æ±‚å¼‚å¸¸: {e}")


def guess_openai_methods(model_id):
    """æ ¹æ®æ¨¡å‹ ID æ¨æ–­æ”¯æŒçš„æ¥å£ç±»å‹"""
    mid = model_id.lower()
    if any(x in mid for x in ["embed", "bge-", "e5-", "gte-"]):
        return ["embedContent"]
    if any(x in mid for x in ["tts", "whisper", "audio", "speech"]):
        return []
    if any(x in mid for x in ["dall-e", "stable-diffusion", "flux", "imagen", "cogview"]):
        return ["predict"]
    if any(x in mid for x in ["rerank", "reranker"]):
        return []
    return ["generateContent"]


def openai_fetch_models(base_url, api_key, provider_name):
    """ä» OpenAI å…¼å®¹ API è·å–æ‰€æœ‰æ¨¡å‹å¹¶è§„æ ¼åŒ–ä¸ºç»Ÿä¸€æ ¼å¼"""
    status, data, _ = openai_api_request(f"{base_url}/models", api_key)
    if status != 200:
        err_msg = data.get("error", {}).get("message", f"HTTP {status}")
        if status in (401, 403):
            raise PermissionError(f"å¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ: {err_msg}")
        elif status == 429:
            raise ConnectionError(f"è¯·æ±‚é¢‘ç‡è¶…é™: {err_msg}")
        else:
            raise RuntimeError(f"è¯·æ±‚å¤±è´¥ ({status}): {err_msg}")

    raw_models = data.get("data", [])
    if not raw_models and data.get("models"):
        raw_models = data["models"]
    if not raw_models:
        return []

    models = []
    for m in raw_models:
        model_id = m.get("id", "")
        methods = guess_openai_methods(model_id)
        input_limit = (m.get("context_length") or m.get("max_context_length")
                       or m.get("context_window") or m.get("max_input_tokens"))
        output_limit = (m.get("max_output_tokens") or m.get("max_completion_tokens")
                        or m.get("max_tokens"))
        model = {
            "name": f"models/{model_id}",
            "displayName": model_id,
            "description": m.get("description") or f"Provider: {provider_name}",
            "supportedGenerationMethods": methods,
            "inputTokenLimit": input_limit,
            "outputTokenLimit": output_limit,
            "_provider_format": FORMAT_OPENAI,
            "_model_id": model_id,
            "_owned_by": m.get("owned_by", ""),
        }
        fill_model_specs(model)  # è¡¥å…¨ API æœªè¿”å›çš„ token é™é¢
        models.append(model)
    return models


def openai_test_model(base_url, api_key, model):
    """æµ‹è¯• OpenAI å…¼å®¹ API çš„å•ä¸ªæ¨¡å‹ï¼Œè¿”å›ä¸­æ–‡é”™è¯¯æç¤º"""
    model_id = model.get("_model_id") or model.get("name", "").replace("models/", "")
    methods = model.get("supportedGenerationMethods", [])
    try:
        if "generateContent" in methods:
            payload = {
                "model": model_id,
                "messages": [{"role": "user", "content": "Say OK"}],
                "max_tokens": 10,
            }
            status, data, _ = openai_api_request(
                f"{base_url}/chat/completions", api_key, data=payload)
            if status == 200:
                txt = (data.get("choices", [{}])[0]
                       .get("message", {}).get("content", "").strip()[:30])
                return True, txt or "(ç©ºå“åº”)"
            else:
                err = data.get("error", {})
                raw_msg = err.get("message", "") if isinstance(err, dict) else str(err)
                cn_msg = translate_error(status, raw_msg)
                return False, cn_msg[:60]
        elif "embedContent" in methods:
            payload = {"model": model_id, "input": "Hello"}
            status, data, _ = openai_api_request(
                f"{base_url}/embeddings", api_key, data=payload)
            if status == 200:
                emb = data.get("data", [{}])
                dim = len(emb[0].get("embedding", [])) if emb else 0
                return True, f"ç»´åº¦ {dim}"
            else:
                err = data.get("error", {})
                raw_msg = err.get("message", "") if isinstance(err, dict) else str(err)
                cn_msg = translate_error(status, raw_msg)
                return False, cn_msg[:60]
        else:
            return None, "æ— å¯æµ‹è¯•æ¥å£"
    except ConnectionError as e:
        return False, str(e)[:50]
    except Exception as e:
        return False, f"æœªçŸ¥é”™è¯¯: {str(e)[:40]}"


# â”€â”€â”€ æ¨¡å‹åˆ†ç±»ä¸åˆ†ç»„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def classify_model(model):
    """å°†æ¨¡å‹åˆ†åˆ°ä¸€ä¸ªç³»åˆ—ä¸­ï¼ˆåŒæ—¶æ”¯æŒ Gemini å’Œ OpenAI æ ¼å¼ï¼‰"""
    if model.get("_provider_format") == FORMAT_OPENAI:
        return classify_openai_model(model)
    # â”€â”€ Gemini åˆ†ç±» â”€â”€
    name = model.get("name", "").lower()
    if "gemini-3" in name:
        return "Gemini 3"
    if "gemini-2.5-pro" in name:
        return "Gemini 2.5 Pro"
    if "gemini-2.5-flash-lite" in name:
        return "Gemini 2.5 Flash-Lite"
    if "gemini-2.5-flash" in name:
        return "Gemini 2.5 Flash"
    if "gemini-2.0-flash-lite" in name:
        return "Gemini 2.0 Flash-Lite"
    if "gemini-2.0-flash" in name:
        return "Gemini 2.0 Flash"
    if "gemini-exp" in name or "gemini-flash" in name or "gemini-pro" in name:
        return "Gemini (å…¶ä»–)"
    if "gemma" in name:
        return "Gemma å¼€æºæ¨¡å‹"
    if "embedding" in name or "embed" in name:
        return "åµŒå…¥æ¨¡å‹"
    if "imagen" in name:
        return "Imagen å›¾åƒç”Ÿæˆ"
    if "veo" in name:
        return "Veo è§†é¢‘ç”Ÿæˆ"
    if "deep-research" in name:
        return "Deep Research"
    if "robotics" in name:
        return "Gemini Robotics"
    return "å…¶ä»–"


def classify_openai_model(model):
    """å°† OpenAI å…¼å®¹æ ¼å¼æ¨¡å‹åˆ†åˆ°ä¸€ä¸ªç³»åˆ—ä¸­"""
    mid = (model.get("_model_id") or model.get("name", "").replace("models/", "")).lower()
    # DeepSeek
    if "deepseek" in mid:
        if "coder" in mid:    return "DeepSeek Coder"
        if "reasoner" in mid or "-r1" in mid: return "DeepSeek Reasoner"
        return "DeepSeek"
    # Qwen
    if "qwen" in mid:
        if "vl" in mid:       return "Qwen è§†è§‰"
        if "coder" in mid:    return "Qwen Coder"
        return "Qwen"
    # GPT
    if mid.startswith("gpt-") or mid.startswith("chatgpt"):
        if "4o" in mid:       return "GPT-4o"
        if "4" in mid:        return "GPT-4"
        if "3.5" in mid:      return "GPT-3.5"
        return "GPT"
    if mid.startswith(("o1", "o3", "o4")):
        return "OpenAI o-ç³»åˆ—"
    # Claude
    if "claude" in mid:
        return "Claude"
    # Llama
    if "llama" in mid or "meta-llama" in mid:
        return "Llama"
    # Mistral
    if "mistral" in mid or "mixtral" in mid:
        return "Mistral"
    # GLM
    if "glm" in mid or "chatglm" in mid:
        return "GLM"
    # Moonshot
    if "moonshot" in mid or "kimi" in mid:
        return "Moonshot"
    # Hunyuan (è…¾è®¯)
    if "hunyuan" in mid:
        return "æ··å…ƒ"
    # Spark (è®¯é£)
    if "spark" in mid or "generalv" in mid or "4.0ultra" in mid:
        return "æ˜Ÿç«"
    # Yi
    if mid.startswith("yi-"):
        return "Yi"
    # Gemini / Gemma via proxy
    if "gemini" in mid:
        return "Gemini"
    if "gemma" in mid:
        return "Gemma"
    # Embedding
    if any(x in mid for x in ["embed", "bge-", "e5-", "gte-"]):
        return "åµŒå…¥æ¨¡å‹"
    # Image
    if any(x in mid for x in ["dall-e", "flux", "stable-diffusion", "sdxl", "cogview"]):
        return "å›¾åƒç”Ÿæˆ"
    # Audio
    if any(x in mid for x in ["tts", "whisper", "speech"]):
        return "è¯­éŸ³"
    # Rerank
    if "rerank" in mid:
        return "é‡æ’åº"
    return "å…¶ä»–"


SERIES_ORDER = [
    "Gemini 3", "Gemini 2.5 Pro", "Gemini 2.5 Flash", "Gemini 2.5 Flash-Lite",
    "Gemini 2.0 Flash", "Gemini 2.0 Flash-Lite", "Gemini (å…¶ä»–)",
    "Gemma å¼€æºæ¨¡å‹", "åµŒå…¥æ¨¡å‹", "Imagen å›¾åƒç”Ÿæˆ", "Veo è§†é¢‘ç”Ÿæˆ",
    "Deep Research", "Gemini Robotics", "å…¶ä»–"
]

SERIES_ICONS = {
    # Gemini
    "Gemini 3": "ğŸš€", "Gemini 2.5 Pro": "ğŸ’", "Gemini 2.5 Flash": "âš¡",
    "Gemini 2.5 Flash-Lite": "ğŸ’¡", "Gemini 2.0 Flash": "âš¡", "Gemini 2.0 Flash-Lite": "ğŸ’¡",
    "Gemini (å…¶ä»–)": "ğŸ”®", "Gemma å¼€æºæ¨¡å‹": "ğŸ”“", "Imagen å›¾åƒç”Ÿæˆ": "ğŸ¨",
    "Veo è§†é¢‘ç”Ÿæˆ": "ğŸ¬", "Deep Research": "ğŸ”¬", "Gemini Robotics": "ğŸ¤–",
    # OpenAI-compatible
    "DeepSeek": "ğŸ”¹", "DeepSeek Coder": "ğŸ’»", "DeepSeek Reasoner": "ğŸ§ ",
    "Qwen": "â˜ï¸", "Qwen è§†è§‰": "ğŸ‘ï¸", "Qwen Coder": "ğŸ’»",
    "GPT-4": "ğŸ’", "GPT-4o": "âš¡", "GPT-3.5": "ğŸ’¡", "GPT": "ğŸŸ¢", "OpenAI o-ç³»åˆ—": "ğŸ§ ",
    "Claude": "ğŸŸ¤",
    "Llama": "ğŸ¦™", "Mistral": "â“‚ï¸", "GLM": "ğŸŸ£", "Moonshot": "ğŸŒ™",
    "Yi": "ğŸŒ", "æ··å…ƒ": "ğŸ§", "æ˜Ÿç«": "âœ¨", "Gemini": "ğŸ”µ", "Gemma": "ğŸ”“",
    "åµŒå…¥æ¨¡å‹": "ğŸ“", "å›¾åƒç”Ÿæˆ": "ğŸ¨", "è¯­éŸ³": "ğŸ”Š", "é‡æ’åº": "ğŸ”€", "å…¶ä»–": "ğŸ“¦",
}

# â”€â”€â”€ é…é¢é™é¢åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Google Gemini API å…è´¹å±‚ (Free Tier) å‚è€ƒé™é¢
# æ•°æ®æ¥æº: https://ai.google.dev/pricing (2025)
# ä»˜è´¹å±‚ (Pay-as-you-go) é™é¢é€šå¸¸é«˜æ•°ç™¾å€ï¼Œä¸”æ— æ¯æ—¥è¯·æ±‚é™åˆ¶
# RPM = æ¯åˆ†é’Ÿè¯·æ±‚æ•°, TPM = æ¯åˆ†é’Ÿ Token æ•°, RPD = æ¯æ—¥è¯·æ±‚æ•°
KNOWN_FREE_LIMITS = {
    "models/gemini-2.5-pro":               {"rpm": 5,   "tpm": 250_000,   "rpd": 25},
    "models/gemini-2.5-flash":             {"rpm": 10,  "tpm": 250_000,   "rpd": 500},
    "models/gemini-2.5-flash-lite":        {"rpm": 30,  "tpm": 1_000_000, "rpd": 3_000},
    "models/gemini-2.5-flash-preview-09-2025":       {"rpm": 10,  "tpm": 250_000,   "rpd": 500},
    "models/gemini-2.5-flash-lite-preview-09-2025":  {"rpm": 30,  "tpm": 1_000_000, "rpd": 3_000},
    "models/gemini-2.5-flash-image":       {"rpm": 10,  "tpm": 250_000,   "rpd": 500},
    "models/gemini-2.0-flash":             {"rpm": 15,  "tpm": 1_000_000, "rpd": 1_500},
    "models/gemini-2.0-flash-001":         {"rpm": 15,  "tpm": 1_000_000, "rpd": 1_500},
    "models/gemini-2.0-flash-exp-image-generation": {"rpm": 10, "tpm": 1_000_000, "rpd": 1_500},
    "models/gemini-2.0-flash-lite":        {"rpm": 30,  "tpm": 1_000_000, "rpd": 3_000},
    "models/gemini-2.0-flash-lite-001":    {"rpm": 30,  "tpm": 1_000_000, "rpd": 3_000},
    "models/gemini-exp-1206":              {"rpm": 10,  "tpm": 1_000_000, "rpd": 50},
    "models/gemini-3-pro-preview":         {"rpm": 5,   "tpm": 250_000,   "rpd": 25},
    "models/gemini-3-flash-preview":       {"rpm": 10,  "tpm": 250_000,   "rpd": 500},
    "models/gemini-3-pro-image-preview":   {"rpm": 5,   "tpm": 250_000,   "rpd": 25},
    "models/nano-banana-pro-preview":      {"rpm": 5,   "tpm": 250_000,   "rpd": 25},
    "models/gemini-flash-latest":          {"rpm": 10,  "tpm": 250_000,   "rpd": 500},
    "models/gemini-flash-lite-latest":     {"rpm": 30,  "tpm": 1_000_000, "rpd": 3_000},
    "models/gemini-pro-latest":            {"rpm": 5,   "tpm": 250_000,   "rpd": 25},
    "models/gemma-3-1b-it":               {"rpm": 30,  "tpm": 1_000_000, "rpd": 14_400},
    "models/gemma-3-4b-it":               {"rpm": 30,  "tpm": 1_000_000, "rpd": 14_400},
    "models/gemma-3-12b-it":              {"rpm": 30,  "tpm": 1_000_000, "rpd": 14_400},
    "models/gemma-3-27b-it":              {"rpm": 30,  "tpm": 1_000_000, "rpd": 14_400},
    "models/gemma-3n-e4b-it":             {"rpm": 30,  "tpm": 1_000_000, "rpd": 14_400},
    "models/gemma-3n-e2b-it":             {"rpm": 30,  "tpm": 1_000_000, "rpd": 14_400},
    "models/gemini-robotics-er-1.5-preview": {"rpm": 5, "tpm": 250_000, "rpd": 25},
}

def parse_rate_limit_headers(headers):
    """ä» HTTP å“åº”å¤´ä¸­è§£æé€Ÿç‡é™åˆ¶ä¿¡æ¯"""
    info = {}
    h = {k.lower(): v for k, v in headers.items()}

    header_map = [
        ("x-ratelimit-limit-requests", "rpm"),
        ("x-ratelimit-remaining-requests", "rpm_remaining"),
        ("x-ratelimit-limit-tokens", "tpm"),
        ("x-ratelimit-remaining-tokens", "tpm_remaining"),
        ("x-ratelimit-limit-requests-per-day", "rpd"),
        ("x-ratelimit-remaining-requests-per-day", "rpd_remaining"),
        ("x-ratelimit-limit", "limit"),
        ("x-ratelimit-remaining", "remaining"),
        ("retry-after", "retry_after"),
    ]
    for key_pattern, field in header_map:
        if key_pattern in h:
            try:
                info[field] = int(h[key_pattern])
            except (ValueError, TypeError):
                info[field] = h[key_pattern]

    # æ”¶é›†æ‰€æœ‰é™é¢ç›¸å…³çš„åŸå§‹å¤´
    info["_raw"] = {k: v for k, v in headers.items()
                    if any(x in k.lower() for x in ["ratelimit", "rate-limit", "quota", "retry"])}
    return info


def fetch_all_quotas(base_url, api_key, models, test_results, api_format=FORMAT_GEMINI):
    """è·å–æ‰€æœ‰å¯ç”¨æ–‡æœ¬ç”Ÿæˆæ¨¡å‹çš„é…é¢ä¿¡æ¯
    å¯¹æ¯ä¸ªå¯ç”¨æ¨¡å‹å‘é€ä¸€æ¬¡è½»é‡è¯·æ±‚ä»¥æ•è·å“åº”å¤´ä¸­çš„é€Ÿç‡é™åˆ¶ä¿¡æ¯ï¼Œ
    æ— æ³•è·å–æ—¶å›é€€è‡³å·²çŸ¥çš„å…è´¹å±‚å‚è€ƒå€¼ã€‚"""

    # åªåˆ†æå¯ç”¨çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹
    gen_models = [m for m in models
                  if test_results.get(m["name"], (None,))[0] is True
                  and "generateContent" in m.get("supportedGenerationMethods", [])]

    if not gen_models:
        return {}

    print()
    print(c("  â³ æ­£åœ¨æ£€æµ‹å„æ¨¡å‹é…é¢é™åˆ¶...", C.CYAN))
    print()

    quota_data = {}

    for i, model in enumerate(gen_models, 1):
        name = model["name"]
        display = model.get("displayName", name.replace("models/", ""))
        progress_bar(i, len(gen_models), label=display)

        entry = {
            "displayName": display,
            "name": name,
            "inputTokenLimit": model.get("inputTokenLimit"),
            "outputTokenLimit": model.get("outputTokenLimit"),
            "rpm": None,
            "tpm": None,
            "rpd": None,
            "source": "æœªçŸ¥",
            "headers_raw": {},
        }

        # ç¬¬ 1 æ­¥: å‘é€è½»é‡è¯·æ±‚ï¼Œæ•è·å“åº”å¤´
        try:
            if api_format == FORMAT_GEMINI:
                url = f"{base_url}/{name}:generateContent?key={api_key}"
                payload = {"contents": [{"parts": [{"text": "Hi"}]}],
                           "generationConfig": {"maxOutputTokens": 1}}
                resp = _session.post(url, json=payload, timeout=30)
            else:
                model_id = model.get("_model_id") or name.replace("models/", "")
                payload = {"model": model_id,
                           "messages": [{"role": "user", "content": "Hi"}],
                           "max_tokens": 1}
                resp = _session.post(f"{base_url}/chat/completions", json=payload,
                                     headers={"Authorization": f"Bearer {api_key}",
                                              "Content-Type": "application/json"},
                                     timeout=30)
            header_info = parse_rate_limit_headers(dict(resp.headers))
            entry["headers_raw"] = header_info.get("_raw", {})

            if "rpm" in header_info and isinstance(header_info["rpm"], int):
                entry["rpm"] = header_info["rpm"]
                entry["source"] = "API å“åº”å¤´"
            if "tpm" in header_info and isinstance(header_info["tpm"], int):
                entry["tpm"] = header_info["tpm"]
            if "rpd" in header_info and isinstance(header_info["rpd"], int):
                entry["rpd"] = header_info["rpd"]
        except Exception:
            pass

        # ç¬¬ 2 æ­¥: å›é€€è‡³å·²çŸ¥å‚è€ƒé™é¢
        if entry["rpm"] is None:
            if name in KNOWN_FREE_LIMITS:
                known = KNOWN_FREE_LIMITS[name]
                entry["rpm"] = known.get("rpm")
                entry["tpm"] = known.get("tpm")
                entry["rpd"] = known.get("rpd")
                entry["source"] = "å‚è€ƒå€¼ (Google å®˜æ–¹)"
            else:
                # å°è¯•å‰ç¼€åŒ¹é…
                for known_name, known_limits in KNOWN_FREE_LIMITS.items():
                    if name.startswith(known_name) or known_name.startswith(name):
                        entry["rpm"] = known_limits.get("rpm")
                        entry["tpm"] = known_limits.get("tpm")
                        entry["rpd"] = known_limits.get("rpd")
                        entry["source"] = "å‚è€ƒå€¼ (è¿‘ä¼¼åŒ¹é…)"
                        break

        # ç¬¬ 3 æ­¥: è®¡ç®—æ¯æ—¥æœ€å¤§è¾“å‡ºååé‡
        output_limit = entry.get("outputTokenLimit") or 0
        rpd = entry.get("rpd") or 0
        tpm = entry.get("tpm") or 0

        daily_by_rpd = rpd * output_limit if rpd else None
        daily_by_tpm = tpm * 1440 if tpm else None  # 1440 åˆ†é’Ÿ/å¤©

        if daily_by_rpd and daily_by_tpm:
            entry["daily_max_output"] = min(daily_by_rpd, daily_by_tpm)
        elif daily_by_rpd:
            entry["daily_max_output"] = daily_by_rpd
        elif daily_by_tpm:
            entry["daily_max_output"] = daily_by_tpm
        else:
            entry["daily_max_output"] = None

        quota_data[name] = entry

        if i % 3 == 0:
            time.sleep(0.2)

    clear_line()
    print(c(f"  âœ… å·²æ£€æµ‹ {len(quota_data)} ä¸ªå¯ç”¨æ¨¡å‹çš„é…é¢", C.GREEN + C.BOLD))
    return quota_data


def print_quota_report(quota_data):
    """æ‰“å°é…é¢å¯¹æ¯”æŠ¥å‘Šè¡¨æ ¼ï¼ŒæŒ‰æ¯æ—¥æœ€å¤§ååé‡é™åºæ’åˆ—"""
    if not quota_data:
        return

    sorted_models = sorted(quota_data.values(),
                           key=lambda x: x.get("daily_max_output") or 0,
                           reverse=True)

    print()
    print(c("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.MAGENTA))
    print(c("  â•‘", C.MAGENTA) + c("                      ğŸ“Š æ¨¡å‹é…é¢ä¸ååé‡åˆ†æ                            ", C.BOLD) + c("â•‘", C.MAGENTA))
    print(c("  â•‘", C.MAGENTA) + c("                    æ’åæŒ‰æ¯æ—¥æœ€å¤§è¾“å‡ºååé‡æ’åº                          ", C.GRAY) + c("â•‘", C.MAGENTA))
    print(c("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.MAGENTA))
    print()

    # è¡¨å¤´
    hdr = f"  {'æ’å':>4s}  {'æ¨¡å‹åç§°':<26s}  {'RPM':>5s}  {'TPM':>8s}  {'RPD':>6s}  {'è¾“å‡º/è¯·æ±‚':>8s}  {'æ¯æ—¥æœ€å¤§åå':>12s}"
    print(c(hdr, C.BOLD))
    divider("â”€", 82)

    medals = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"]

    for idx, entry in enumerate(sorted_models):
        rank = idx + 1
        medal = medals[idx] if idx < 3 else "  "

        display = entry["displayName"]
        if len(display) > 24:
            display = display[:22] + ".."
        rpm_s = str(entry.get("rpm")) if entry.get("rpm") is not None else "?"
        tpm_s = fmt_tokens(entry.get("tpm")) if entry.get("tpm") else "?"
        rpd_s = str(entry.get("rpd")) if entry.get("rpd") is not None else "?"
        out_s = fmt_tokens(entry.get("outputTokenLimit"))
        daily_s = fmt_tokens(entry.get("daily_max_output")) if entry.get("daily_max_output") else "?"

        if rank <= 3:
            nc, dc = C.GREEN + C.BOLD, C.GREEN + C.BOLD
        elif rank <= 6:
            nc, dc = C.WHITE, C.WHITE
        else:
            nc, dc = C.GRAY, C.GRAY

        src_mark = c(" âš¡", C.CYAN) if "API" in entry.get("source", "") else ""

        print(f"  {medal}{rank:>2d}  {c(f'{display:<26s}', nc)}  "
              f"{c(f'{rpm_s:>5s}', C.WHITE)}  {c(f'{tpm_s:>8s}', C.WHITE)}  "
              f"{c(f'{rpd_s:>6s}', C.WHITE)}  {c(f'{out_s:>8s}', C.WHITE)}  "
              f"{c(f'{daily_s:>12s}', dc)}{src_mark}")

    print()
    divider("â”€", 82)

    # æ•°æ®æ¥æºè¯´æ˜
    sources = set(e.get("source", "") for e in quota_data.values())
    print(f"  {c('ğŸ“Œ æ•°æ®æ¥æº:', C.DIM)} ", end="")
    if "API å“åº”å¤´" in sources:
        print(c("âš¡ = API å®æ—¶å“åº”å¤´", C.CYAN), end="  ")
    if any("å‚è€ƒ" in s for s in sources):
        print(c("å…¶ä½™ = Google å®˜æ–¹æ–‡æ¡£å‚è€ƒå€¼ (å…è´¹å±‚)", C.GRAY), end="")
    print()
    print(f"  {c('ğŸ’¡ æ¯æ—¥æœ€å¤§åå = min(RPD Ã— å•æ¬¡æœ€å¤§è¾“å‡º, TPM Ã— 1440 åˆ†é’Ÿ)', C.DIM)}")
    print(f"  {c('   ä»˜è´¹è´¦æˆ· (Pay-as-you-go) é™é¢é€šå¸¸é«˜æ•°ç™¾å€, ä¸”æ— æ¯æ—¥è¯·æ±‚é™åˆ¶', C.DIM)}")
    print()

    # å‰ä¸‰æ¨è
    if sorted_models:
        print(f"  {c('ğŸ† å¤§é‡ Token å¤„ç†æ¨è:', C.BOLD + C.GREEN)}")
        for i, m in enumerate(sorted_models[:3]):
            d = m.get("daily_max_output")
            if d:
                prefix = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i]
                print(f"     {prefix} {c(m['displayName'], C.GREEN + C.BOLD)} â€” "
                      f"æ¯æ—¥æœ€å¤š ~{c(fmt_tokens(d), C.GREEN + C.BOLD)} tokens è¾“å‡º")
        print()


def prompt_token_calculator(quota_data):
    """äº¤äº’å¼ Token éœ€æ±‚è®¡ç®—å™¨ï¼šç”¨æˆ·è¾“å…¥éœ€å¤„ç†çš„ Token æ€»é‡ï¼Œ
    è‡ªåŠ¨ä¼°ç®—å„æ¨¡å‹æ‰€éœ€æ—¶é—´å¹¶æ’åã€‚"""
    if not quota_data:
        return

    try:
        raw = input(c("  ğŸ“ è¾“å…¥ä½ éœ€è¦çš„æ€» Token æ•° (ä¾‹: 10000000 æˆ– 10Mï¼Œç›´æ¥å›è½¦è·³è¿‡): ",
                      C.BOLD + C.WHITE)).strip()
    except (EOFError, KeyboardInterrupt):
        return

    if not raw:
        return

    # è§£æè¾“å…¥
    raw = raw.upper().replace(",", "").replace(" ", "").replace("_", "")
    try:
        if raw.endswith("B"):
            total_tokens = int(float(raw[:-1]) * 1_000_000_000)
        elif raw.endswith("M"):
            total_tokens = int(float(raw[:-1]) * 1_000_000)
        elif raw.endswith("K"):
            total_tokens = int(float(raw[:-1]) * 1_000)
        else:
            total_tokens = int(float(raw))
    except ValueError:
        print(c("  âš ï¸  æ— æ³•è§£æè¾“å…¥ï¼Œè·³è¿‡è®¡ç®—ã€‚", C.YELLOW))
        return

    if total_tokens <= 0:
        return

    sorted_models = sorted(quota_data.values(),
                           key=lambda x: x.get("daily_max_output") or 0,
                           reverse=True)

    print()
    print(c(f"  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.CYAN))
    print(c(f"  â•‘", C.CYAN) + c(f"          ğŸ§® Token éœ€æ±‚é¢„ä¼°: å…±éœ€ {fmt_tokens(total_tokens)} tokens", C.BOLD)
          + " " * max(0, 32 - len(fmt_tokens(total_tokens))) + c("â•‘", C.CYAN))
    print(c(f"  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.CYAN))
    print()

    hdr = f"  {'æ¨¡å‹åç§°':<28s}  {'æ¯æ—¥åå':>10s}  {'é¢„è®¡è€—æ—¶':>16s}  {'æ‰€éœ€è¯·æ±‚æ•°':>10s}"
    print(c(hdr, C.BOLD))
    divider("â”€", 72)

    for entry in sorted_models:
        daily = entry.get("daily_max_output")
        if not daily or daily == 0:
            continue

        display = entry["displayName"]
        if len(display) > 26:
            display = display[:24] + ".."

        days = total_tokens / daily
        output_per_req = entry.get("outputTokenLimit") or 1
        num_requests = (total_tokens + output_per_req - 1) // output_per_req

        # æ ¼å¼åŒ–æ—¶é—´
        if days < 1:
            hours = days * 24
            if hours < 1:
                minutes = hours * 60
                time_str = f"~{minutes:.0f} åˆ†é’Ÿ"
            else:
                time_str = f"~{hours:.1f} å°æ—¶"
        elif days < 7:
            time_str = f"~{days:.1f} å¤©"
        else:
            time_str = f"~{days:.0f} å¤© ({days / 7:.1f} å‘¨)"

        # é¢œè‰²
        if days < 1:
            tc = C.GREEN + C.BOLD
        elif days < 3:
            tc = C.WHITE
        elif days < 7:
            tc = C.YELLOW
        else:
            tc = C.RED

        print(f"  {c(f'{display:<28s}', C.WHITE)}  {c(fmt_tokens(daily) + '/å¤©', C.GRAY):>16s}"
              f"  {c(f'{time_str:>16s}', tc)}  {c(f'{num_requests:>10,d}', C.GRAY)}")

    print()

# â”€â”€â”€ å¯è§†åŒ–è¾“å‡º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_model_row(model, test_result=None, idx=0):
    """æ‰“å°ä¸€è¡Œæ¨¡å‹ä¿¡æ¯"""
    display = model.get("displayName", "")
    model_id = model.get("name", "").replace("models/", "")
    methods = model.get("supportedGenerationMethods", [])
    inp = fmt_tokens(model.get("inputTokenLimit"))
    out = fmt_tokens(model.get("outputTokenLimit"))

    # å¯ç”¨æ€§æ ‡è®°
    if test_result is not None:
        ok, msg = test_result
        if ok is True:
            status = c(" âœ“ ", C.GREEN + C.BOLD)
        elif ok is False:
            status = c(" âœ— ", C.RED + C.BOLD)
        else:
            status = c(" - ", C.GRAY)
    else:
        status = c("   ", C.GRAY)

    # èƒ½åŠ›æ ‡ç­¾ï¼ˆç®€çŸ­ï¼‰
    caps = []
    if "generateContent" in methods:
        caps.append(c("ç”Ÿæˆ", C.GREEN))
    if "embedContent" in methods or "embedText" in methods:
        caps.append(c("åµŒå…¥", C.YELLOW))
    if "bidiGenerateContent" in methods:
        caps.append(c("å®æ—¶", C.MAGENTA))
    if "predict" in methods or "predictLongRunning" in methods:
        caps.append(c("é¢„æµ‹", C.CYAN))
    caps_str = c("|", C.GRAY).join(caps) if caps else c("--", C.GRAY)

    # ä¸»è¡Œ
    idx_str = c(f"{idx:>2}", C.GRAY)
    name_str = c(display if display else model_id, C.WHITE + C.BOLD)
    id_str = c(model_id, C.GRAY)

    print(f"  {status} {idx_str}  {name_str}")
    print(f"         {id_str}")
    print(f"         {caps_str}   {c('è¾“å…¥', C.DIM)} {c(inp, C.WHITE)}  {c('è¾“å‡º', C.DIM)} {c(out, C.WHITE)}", end="")

    # æµ‹è¯•è¯¦æƒ…
    if test_result is not None:
        ok, msg = test_result
        if ok is True:
            print(f"  {c(msg, C.GREEN)}", end="")
        elif ok is False:
            print(f"  {c(msg[:45], C.RED)}", end="")
    print()
    print()

def print_summary(models, test_results):
    """æ‰“å°ç¾è§‚çš„ç»Ÿè®¡æ‘˜è¦"""
    total = len(models)
    tested = {k: v for k, v in test_results.items()}
    ok_count = sum(1 for s, _ in tested.values() if s is True)
    fail_count = sum(1 for s, _ in tested.values() if s is False)
    skip_count = sum(1 for s, _ in tested.values() if s is None)

    gen_count = sum(1 for m in models if "generateContent" in m.get("supportedGenerationMethods", []))
    emb_count = sum(1 for m in models if "embedContent" in m.get("supportedGenerationMethods", [])
                    or "embedText" in m.get("supportedGenerationMethods", []))
    img_count = sum(1 for m in models if "predict" in m.get("supportedGenerationMethods", [])
                    or "predictLongRunning" in m.get("supportedGenerationMethods", []))

    print()
    print(c("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.BLUE))
    print(c("  â•‘", C.BLUE) + c("                       ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦                       ", C.BOLD) + c("â•‘", C.BLUE))
    print(c("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£", C.BLUE))

    # å¯ç”¨æ€§ç»Ÿè®¡ - å¯è§†åŒ–æ¡
    bar_width = 40
    ok_w = int(bar_width * ok_count / total) if total else 0
    fail_w = int(bar_width * fail_count / total) if total else 0
    skip_w = bar_width - ok_w - fail_w

    bar = c("â–ˆ" * ok_w, C.GREEN) + c("â–ˆ" * fail_w, C.RED) + c("â–ˆ" * skip_w, C.GRAY)
    print(c("  â•‘", C.BLUE) + f"  {bar}               " + c("â•‘", C.BLUE))
    print(c("  â•‘", C.BLUE) + f"  {c('â– ', C.GREEN)} å¯ç”¨ {c(str(ok_count), C.GREEN + C.BOLD):>12s}   {c('â– ', C.RED)} ä¸å¯ç”¨ {c(str(fail_count), C.RED + C.BOLD):>10s}   {c('â– ', C.GRAY)} è·³è¿‡ {c(str(skip_count), C.GRAY):>8s}     " + c("â•‘", C.BLUE))
    print(c("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£", C.BLUE))

    # æ¨¡å‹ç±»å‹ç»Ÿè®¡
    print(c("  â•‘", C.BLUE) + f"  {c('æ¨¡å‹æ€»æ•°', C.DIM)}         {c(str(total), C.WHITE + C.BOLD):>10s}                                " + c("â•‘", C.BLUE))
    print(c("  â•‘", C.BLUE) + f"  {c('æ–‡æœ¬ç”Ÿæˆæ¨¡å‹', C.GREEN)}     {c(str(gen_count), C.GREEN + C.BOLD):>10s}                                " + c("â•‘", C.BLUE))
    print(c("  â•‘", C.BLUE) + f"  {c('åµŒå…¥æ¨¡å‹', C.YELLOW)}         {c(str(emb_count), C.YELLOW + C.BOLD):>10s}                                " + c("â•‘", C.BLUE))
    print(c("  â•‘", C.BLUE) + f"  {c('å›¾åƒ/è§†é¢‘æ¨¡å‹', C.CYAN)}   {c(str(img_count), C.CYAN + C.BOLD):>12s}                                " + c("â•‘", C.BLUE))

    print(c("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.BLUE))
    print()

def export_json(api_key, base_url, models, test_results, quota_data=None):
    """å¯¼å‡ºç»“æœåˆ° JSON (åŒ…å«é…é¢åˆ†æ)"""
    export_data = {
        "api_key_prefix": api_key[:8] + "..." if len(api_key) > 8 else "***",
        "base_url": base_url,
        "test_time": time.strftime("%Y-%m-%d %H:%M:%S"),
        "total_models": len(models),
        "available": sum(1 for s, _ in test_results.values() if s is True),
        "unavailable": sum(1 for s, _ in test_results.values() if s is False),
        "models": []
    }
    for model in models:
        info = {
            "name": model.get("name"),
            "displayName": model.get("displayName"),
            "description": model.get("description"),
            "supportedMethods": model.get("supportedGenerationMethods", []),
            "inputTokenLimit": model.get("inputTokenLimit"),
            "outputTokenLimit": model.get("outputTokenLimit"),
        }
        if model.get("name") in test_results:
            s, msg = test_results[model["name"]]
            info["testResult"] = {"available": s, "message": msg}
        # é™„åŠ é…é¢ä¿¡æ¯
        if quota_data and model.get("name") in quota_data:
            q = quota_data[model["name"]]
            info["quota"] = {
                "rpm": q.get("rpm"),
                "tpm": q.get("tpm"),
                "rpd": q.get("rpd"),
                "dailyMaxOutput": q.get("daily_max_output"),
                "source": q.get("source"),
            }
        export_data["models"].append(info)

    # é…é¢æ’è¡Œæ‘˜è¦
    if quota_data:
        ranked = sorted(quota_data.values(),
                        key=lambda x: x.get("daily_max_output") or 0,
                        reverse=True)
        export_data["quotaRanking"] = [
            {
                "rank": i + 1,
                "name": e["name"],
                "displayName": e["displayName"],
                "rpm": e.get("rpm"),
                "tpm": e.get("tpm"),
                "rpd": e.get("rpd"),
                "outputTokenLimit": e.get("outputTokenLimit"),
                "dailyMaxOutput": e.get("daily_max_output"),
                "source": e.get("source"),
            }
            for i, e in enumerate(ranked)
        ]

    filename = f"api_test_{time.strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(export_data, f, ensure_ascii=False, indent=2)
    return filename

# â”€â”€â”€ Web ä»£ç†æœåŠ¡å™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def start_web_server(port=8765):
    """å¯åŠ¨æœ¬åœ° Web ä»£ç†æœåŠ¡å™¨ï¼Œä¸º HTML ç‰ˆæä¾› CORS ä»£ç†åŠŸèƒ½ã€‚
    æµè§ˆå™¨é¡µé¢é€šè¿‡ /api/proxy?url=<ç›®æ ‡URL> å‘èµ·è¯·æ±‚ï¼Œ
    æœåŠ¡å™¨è½¬å‘è‡³å®é™… API å¹¶è¿”å›ç»“æœï¼Œç»•è¿‡æµè§ˆå™¨ CORS é™åˆ¶ã€‚"""
    from http.server import HTTPServer, BaseHTTPRequestHandler
    from urllib.parse import urlparse, parse_qs, unquote
    import webbrowser
    import threading

    script_dir = os.path.dirname(os.path.abspath(__file__))
    html_path = os.path.join(script_dir, "index.html")

    if not os.path.exists(html_path):
        print(c("  âŒ æœªæ‰¾åˆ° index.htmlï¼Œè¯·ç¡®è®¤ä¸ gemini_test.py åœ¨åŒä¸€ç›®å½•", C.RED))
        safe_exit(1)

    # åˆ›å»ºç‹¬ç«‹çš„ requests ä¼šè¯ï¼ˆè‡ªåŠ¨ç»§æ‰¿ç³»ç»Ÿä»£ç†ï¼‰
    web_session = requests.Session()
    web_session.verify = False

    class ProxyHandler(BaseHTTPRequestHandler):

        def do_OPTIONS(self):
            """å¤„ç† CORS é¢„æ£€è¯·æ±‚"""
            self.send_response(200)
            self._cors_headers()
            self.end_headers()

        def do_GET(self):
            if self.path == "/" or self.path == "/index.html":
                self._serve_html()
            elif self.path.startswith("/api/proxy"):
                self._handle_proxy("GET")
            else:
                self.send_error(404)

        def do_POST(self):
            if self.path.startswith("/api/proxy"):
                self._handle_proxy("POST")
            else:
                self.send_error(404)

        def _cors_headers(self):
            self.send_header("Access-Control-Allow-Origin", "*")
            self.send_header("Access-Control-Allow-Methods", "GET, POST, OPTIONS")
            self.send_header("Access-Control-Allow-Headers", "*")
            self.send_header("Access-Control-Expose-Headers", "*")

        def _serve_html(self):
            try:
                with open(html_path, "rb") as f:
                    content = f.read()
                self.send_response(200)
                self.send_header("Content-Type", "text/html; charset=utf-8")
                self.send_header("Content-Length", str(len(content)))
                self.end_headers()
                self.wfile.write(content)
            except Exception as e:
                self.send_error(500, str(e))

        def _handle_proxy(self, method):
            """ä»£ç†è½¬å‘è¯·æ±‚åˆ°ç›®æ ‡ API"""
            parsed = urlparse(self.path)
            params = parse_qs(parsed.query)
            target_url = params.get("url", [None])[0]

            if not target_url:
                self.send_response(400)
                self._cors_headers()
                self.send_header("Content-Type", "application/json")
                self.end_headers()
                self.wfile.write(json.dumps(
                    {"error": {"message": "ç¼ºå°‘ url å‚æ•°"}}).encode())
                return

            target_url = unquote(target_url)

            # è¯»å–è¯·æ±‚ä½“
            content_length = int(self.headers.get("Content-Length", 0))
            body = self.rfile.read(content_length) if content_length > 0 else None

            # è½¬å‘è¯·æ±‚å¤´ï¼ˆè¿‡æ»¤æµè§ˆå™¨ä¸“ç”¨å¤´ï¼‰
            skip_headers = {
                "host", "connection", "accept-encoding", "origin",
                "referer", "sec-fetch-mode", "sec-fetch-site",
                "sec-fetch-dest", "sec-ch-ua", "sec-ch-ua-mobile",
                "sec-ch-ua-platform",
            }
            forward_headers = {}
            for key in self.headers:
                if key.lower() not in skip_headers:
                    forward_headers[key] = self.headers[key]

            # è½¬å‘è¯·æ±‚
            try:
                if method == "POST":
                    resp = web_session.post(
                        target_url, headers=forward_headers,
                        data=body, timeout=30)
                else:
                    resp = web_session.get(
                        target_url, headers=forward_headers, timeout=30)

                # è¿”å›å“åº”
                self.send_response(resp.status_code)
                self._cors_headers()

                # è½¬å‘å“åº”å¤´ï¼ˆä¿ç•™ rate-limit ç­‰å…³é”®å¤´ï¼‰
                skip_resp = {"content-encoding", "transfer-encoding",
                             "connection", "content-length"}
                for key, value in resp.headers.items():
                    if key.lower() not in skip_resp:
                        self.send_header(key, value)

                resp_body = resp.content
                self.send_header("Content-Length", str(len(resp_body)))
                self.end_headers()
                self.wfile.write(resp_body)

            except requests.exceptions.ProxyError as e:
                self._send_proxy_error(f"ä»£ç†è¿æ¥å¤±è´¥: {e}")
            except requests.exceptions.ConnectionError as e:
                self._send_proxy_error(f"æ— æ³•è¿æ¥ç›®æ ‡æœåŠ¡å™¨: {e}")
            except requests.exceptions.Timeout:
                self._send_proxy_error("è¯·æ±‚è¶…æ—¶ (30s)")
            except Exception as e:
                self._send_proxy_error(f"ä»£ç†è¯·æ±‚å¼‚å¸¸: {e}")

        def _send_proxy_error(self, msg):
            self.send_response(502)
            self._cors_headers()
            self.send_header("Content-Type", "application/json")
            err_body = json.dumps(
                {"error": {"message": msg}}).encode("utf-8")
            self.send_header("Content-Length", str(len(err_body)))
            self.end_headers()
            self.wfile.write(err_body)

        def log_message(self, format, *args):
            """ç®€åŒ–æ—¥å¿—è¾“å‡º"""
            method = args[0] if args else ""
            if "/api/proxy" in str(method):
                # åªåœ¨ä»£ç†è¯·æ±‚æ—¶è¾“å‡ºç®€çŸ­æ—¥å¿—
                status = args[-1] if len(args) > 1 else ""
                sys.stdout.write(f"\r  ğŸ“¡ {method} â†’ {status}    \n")
                sys.stdout.flush()

    # å°è¯•å¯åŠ¨æœåŠ¡å™¨
    for p in (port, port + 1, port + 2):
        try:
            server = HTTPServer(("127.0.0.1", p), ProxyHandler)
            port = p
            break
        except OSError:
            continue
    else:
        print(c(f"  âŒ ç«¯å£ {port}-{port+2} å‡è¢«å ç”¨ï¼Œæ— æ³•å¯åŠ¨æœåŠ¡", C.RED))
        safe_exit(1)

    url = f"http://localhost:{port}"
    print()
    print(c("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", C.GREEN))
    print(c("  â•‘", C.GREEN) + c("            ğŸŒ Web ä»£ç†æœåŠ¡å·²å¯åŠ¨!                              ", C.BOLD) + c("â•‘", C.GREEN))
    print(c("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", C.GREEN))
    print()
    print(c(f"  ğŸ”— è®¿é—®åœ°å€: {url}", C.CYAN + C.BOLD))
    print(c(f"  ğŸ“¡ ä»£ç†æ¨¡å¼: æ‰€æœ‰ API è¯·æ±‚å°†é€šè¿‡æœ¬åœ°æœåŠ¡å™¨ä¸­è½¬ï¼Œç»•è¿‡ CORS é™åˆ¶", C.GRAY))
    print(c(f"  ğŸ›‘ æŒ‰ Ctrl+C åœæ­¢æœåŠ¡", C.GRAY))
    print()
    divider()

    # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    threading.Timer(0.5, lambda: webbrowser.open(url)).start()

    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print(c("\n\n  âš ï¸  Web æœåŠ¡å·²åœæ­¢ã€‚", C.YELLOW))
        server.server_close()
        safe_exit(0)


# â”€â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    # æ£€æŸ¥ --web å¯åŠ¨æ¨¡å¼
    if "--web" in sys.argv:
        print_header()
        start_web_server()
        return

    print_header()

    # â‘  è·å– API å¯†é’¥
    if len(sys.argv) > 1:
        api_key = sys.argv[1]
        print(c(f"  ğŸ”‘ API å¯†é’¥: {api_key[:8]}...{api_key[-4:]}", C.WHITE))
    else:
        api_key = input(c("  ğŸ”‘ è¯·è¾“å…¥ API å¯†é’¥: ", C.BOLD + C.WHITE)).strip()

    if not api_key:
        print(c("\n  âŒ æœªè¾“å…¥å¯†é’¥ï¼Œé€€å‡ºã€‚\n", C.RED))
        safe_exit(1)

    custom_url = sys.argv[2].rstrip("/") if len(sys.argv) > 2 else None

    # â‘¡ æå‰é…ç½®ä»£ç†ï¼ˆæ¢æµ‹æœåŠ¡å•†æ—¶éœ€è¦ï¼‰
    proxy_port, proxy_name = detect_proxy()
    if proxy_port:
        px = f"http://127.0.0.1:{proxy_port}"
        _session.proxies = {"http": px, "https": px}
        _session.trust_env = False
    else:
        sys_proxies = urllib.request.getproxies()
        if sys_proxies:
            _session.trust_env = True

    # â‘¢ è‡ªåŠ¨è¯†åˆ« API æœåŠ¡å•†
    provider = auto_detect_provider(api_key, custom_url)
    api_format = provider["format"]
    base_url = provider["base_url"]

    # â‘£ ç½‘ç»œè¯Šæ–­
    if api_format == FORMAT_GEMINI:
        base_url = run_network_diagnostic(base_url)
    else:
        run_openai_diagnostic(provider, proxy_port, proxy_name)

    # â‘¤ è·å–æ¨¡å‹åˆ—è¡¨
    print(c("  â³ æ­£åœ¨è·å–æ¨¡å‹åˆ—è¡¨...", C.CYAN))

    try:
        t0 = time.time()
        if api_format == FORMAT_GEMINI:
            models = fetch_models(base_url, api_key)
        else:
            models = openai_fetch_models(base_url, api_key, provider["name"])
        t_fetch = time.time() - t0
    except PermissionError as e:
        print(c(f"\n  âŒ {e}", C.RED))
        print(c("     è¯·ç¡®è®¤å¯†é’¥æ˜¯å¦æ­£ç¡®", C.YELLOW))
        safe_exit(1)
    except ConnectionError as e:
        print(c(f"\n  âŒ {e}", C.RED))
        print(c("     ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜ï¼Œè¯·å‚è€ƒä¸Šæ–¹è¯Šæ–­ç»“æœæ’æŸ¥", C.YELLOW))
        safe_exit(1)
    except Exception as e:
        print(c(f"\n  âŒ {e}", C.RED))
        safe_exit(1)

    if not models:
        print(c("  âš ï¸  å¯†é’¥æœ‰æ•ˆï¼Œä½†æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨æ¨¡å‹ã€‚", C.YELLOW))
        safe_exit(0)

    print(c(f"  âœ… å‘ç° {len(models)} ä¸ªæ¨¡å‹ ({t_fetch:.1f}s)", C.GREEN + C.BOLD))

    # â‘¥ é€ä¸€æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
    print()
    print(c("  â³ æ­£åœ¨é€ä¸€æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§...", C.CYAN))
    print()

    test_results = {}
    t0 = time.time()
    for i, model in enumerate(models, 1):
        model_name = model.get("name", "")
        display = model.get("displayName", model_name.replace("models/", ""))
        progress_bar(i, len(models), label=display)
        if api_format == FORMAT_GEMINI:
            result = test_model(base_url, api_key, model)
        else:
            result = openai_test_model(base_url, api_key, model)
        test_results[model_name] = result
        if i % 5 == 0:
            time.sleep(0.2)
    clear_line()
    t_test = time.time() - t0
    print(c(f"  âœ… å…¨éƒ¨æµ‹è¯•å®Œæˆ ({t_test:.1f}s)", C.GREEN + C.BOLD))

    # â‘¦ æŒ‰ç³»åˆ—åˆ†ç»„å±•ç¤º
    print()
    divider("â•")
    print(c(f"  ğŸ“‹ æ¨¡å‹è¯¦ç»†åˆ—è¡¨ ({provider['icon']} {provider['name']})", C.BOLD))
    divider("â•")

    # åˆ†ç»„
    groups = {}
    for model in models:
        series = classify_model(model)
        groups.setdefault(series, []).append(model)

    # ç¡®å®šç³»åˆ—é¡ºåº
    if api_format == FORMAT_GEMINI:
        ordered_series = [s for s in SERIES_ORDER if s in groups]
        for s in groups:
            if s not in ordered_series:
                ordered_series.append(s)
    else:
        ordered_series = sorted(groups.keys(),
                                key=lambda s: (-len(groups[s]), s))

    idx = 0
    for series in ordered_series:
        group = groups[series]
        icon = SERIES_ICONS.get(series, "ğŸ“¦")

        ok_in_group = sum(1 for m in group
                         if test_results.get(m["name"], (None,))[0] is True)
        total_in_group = len(group)

        print()
        print(f"  {icon} {c(series, C.BOLD + C.WHITE)} {c(f'({ok_in_group}/{total_in_group} å¯ç”¨)', C.GRAY)}")
        divider("â”€", 50)
        print()

        for model in group:
            idx += 1
            result = test_results.get(model.get("name"))
            print_model_row(model, result, idx)

    # â‘§ ç»Ÿè®¡æ‘˜è¦
    print_summary(models, test_results)

    # â‘¨ è´¦æˆ·çŠ¶æ€è¯Šæ–­ (OpenAI å…¼å®¹æœåŠ¡å•†)
    balance_info = {}
    if api_format == FORMAT_OPENAI:
        print(c("  â³ æ­£åœ¨æŸ¥è¯¢è´¦æˆ·ä½™é¢...", C.CYAN))
        balance_info = query_openai_balance(base_url, api_key, provider["name"])
        print_account_diagnosis(provider, api_key, base_url, balance_info,
                                models, test_results)

    # â‘© é…é¢é™é¢åˆ†æ
    quota_data = fetch_all_quotas(base_url, api_key, models, test_results, api_format)
    if quota_data:
        print_quota_report(quota_data)
        prompt_token_calculator(quota_data)

    # â‘ª è‡ªåŠ¨å¯¼å‡º
    filename = export_json(api_key, base_url, models, test_results, quota_data)
    print(c(f"  ğŸ’¾ æµ‹è¯•ç»“æœå·²è‡ªåŠ¨å¯¼å‡ºåˆ°: {filename}", C.GREEN))
    print()

    # â‘« å®Œæˆ
    print(c("  âœ… å…¨éƒ¨æµ‹è¯•æµç¨‹å®Œæˆï¼", C.GREEN + C.BOLD))
    safe_exit(0)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print(c("\n\n  âš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œã€‚", C.YELLOW))
        safe_exit(0)
    except SystemExit:
        raise  # å…è®¸ safe_exit() æ­£å¸¸é€€å‡º
    except Exception as e:
        print(c(f"\n  âŒ ç¨‹åºå‘ç”Ÿæ„å¤–é”™è¯¯: {e}", C.RED))
        import traceback
        traceback.print_exc()
        safe_exit(1)
